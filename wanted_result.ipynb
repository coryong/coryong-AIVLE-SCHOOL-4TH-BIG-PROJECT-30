{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_list= ['데이터분석가', '프론트엔드', '백엔드', '머신러닝 엔지니어', \n",
    "#            '딥러닝 엔지니어','데이터 엔지니어', '데이터 사이언티스트',\n",
    "#            'UI/UX 디자이너', '앱 개발자']\n",
    "\n",
    "job_list = ['데이터 분석가', '프론트엔드 개발자', '백엔드 개발자', 'AI 엔지니어', '데이터 사이언티스트', '데이터 엔지니어', 'UI/UX 디자이너', '앱 개발자']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# job_list = ['데이터 분석가', '프론트엔드 개발자', '백엔드 개발자', 'AI 엔지니어', '데이터 사이언티스트', '데이터 엔지니어', 'UI/UX 디자이너', '앱 개발자']\n",
    "# job_list = {\n",
    "#     '데이터 분석가': 90,\n",
    "#     '프론트엔드 개발자': 280,\n",
    "#     '백엔드 개발자': 340,\n",
    "#     'AI 엔지니어': 40,\n",
    "#     '데이터 사이언티스트': 18,\n",
    "#     '데이터 엔지니어': 50,\n",
    "#     'UI/UX 디자이너': 220, \n",
    "#     '앱 개발자': 90\n",
    "# }\n",
    "job_list = {\n",
    "    '데이터 분석가': 90,\n",
    "    '프론트엔드 개발자': 280,\n",
    "    '백엔드 개발자': 340,\n",
    "    'AI 엔지니어': 40,\n",
    "    '데이터 사이언티스트': 18,\n",
    "    '앱 개발자': 90\n",
    "}\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "job_names = [] # 직업\n",
    "titles = [] # 회사명\n",
    "jobs = [] # 주요업무\n",
    "requirements_list = [] # 자격요건\n",
    "preferentials = [] # 우대사항\n",
    "welfares = [] #복지\n",
    "technology_stacks = [] # 요구 기술스택 및 툴\n",
    "\n",
    "for j, max_i in job_list.items():\n",
    "    url_list = []\n",
    "    url = 'https://www.wanted.co.kr/search?query=' + j + '&tab=position'\n",
    "    driver.get(url)\n",
    "\n",
    "    i = 1 \n",
    "\n",
    "    while i <= max_i:  # Change the condition here\n",
    "        try:\n",
    "            # 페이지 끝까지 스크롤\n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "            \n",
    "            # 특정 요소가 로드될 때까지 기다림\n",
    "            WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, f\"/html/body/div[1]/div[4]/div[3]/div[2]/div[1]/div[4]/div[{i}]/a\")))\n",
    "\n",
    "            link = driver.find_element(By.XPATH, f\"/html/body/div[1]/div[4]/div[3]/div[2]/div[1]/div[4]/div[{i}]/a\")\n",
    "            link = link.get_attribute('href')\n",
    "            url_list.append(link)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        except :\n",
    "            pass\n",
    "\n",
    "    for k in range(len(url_list)):\n",
    "        try :\n",
    "            a = url_list[k]\n",
    "            driver.get(a)\n",
    "            title = driver.find_element(By.CSS_SELECTOR, 'span.JobHeader_companyNameText__uuJyu > a')\n",
    "            job = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[2]/span')\n",
    "            requirements = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[3]/span')\n",
    "            preferential = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[4]/span')\n",
    "            welfare = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[5]/span')\n",
    "            # Scrape the technology stack and tools\n",
    "            tech_stack_elements = driver.find_elements(By.CSS_SELECTOR, '.JobDescription_JobDescription_skill_wrapper__9EdFE .SkillItem_SkillItem__E2WtM')\n",
    "            tech_stack = [element.text for element in tech_stack_elements]\n",
    "            technology_stacks.append(', '.join(tech_stack))  # Combine into a single string\n",
    "            \n",
    "            job_names.append(j)\n",
    "            titles.append(title.text)\n",
    "            jobs.append(job.text)\n",
    "            requirements_list.append(requirements.text)\n",
    "            preferentials.append(preferential.text)\n",
    "            welfares.append(welfare.text)\n",
    "        \n",
    "        except : \n",
    "            pass\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    '직업' : job_names,\n",
    "    '회사명': titles,\n",
    "    '주요업무': jobs,\n",
    "    '자격요건': requirements_list,\n",
    "    '우대사항': preferentials,\n",
    "    '복지': welfares,\n",
    "    '기숤':technology_stacks\n",
    "})\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Define your job list\n",
    "job_list = {\n",
    "    '데이터 분석가': 90,\n",
    "    '프론트엔드 개발자': 280,\n",
    "    '백엔드 개발자': 340,\n",
    "    'AI 엔지니어': 40,\n",
    "    '데이터 사이언티스트': 18,\n",
    "    '앱 개발자': 90\n",
    "}\n",
    "\n",
    "def scrape_jobs():\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    job_names = []  # job\n",
    "    titles = []  # company name\n",
    "    jobs = []  # Main tasks\n",
    "    requirements_list = []  # Qualifications\n",
    "    preferentials = []  # preferences\n",
    "    welfares = []  # welfare\n",
    "    technology_stacks = []  # Required technology stacks and tools\n",
    "\n",
    "    for j, max_i in job_list.items():\n",
    "        url_list = []\n",
    "        url = 'https://www.wanted.co.kr/search?query=' + j + '&tab=position'\n",
    "        driver.get(url)\n",
    "\n",
    "        i = 1\n",
    "    while i <= max_i:  # Change the condition here\n",
    "        try:\n",
    "            # 페이지 끝까지 스크롤\n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "            \n",
    "            # 특정 요소가 로드될 때까지 기다림\n",
    "            WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, f\"/html/body/div[1]/div[4]/div[3]/div[2]/div[1]/div[4]/div[{i}]/a\")))\n",
    "\n",
    "            link = driver.find_element(By.XPATH, f\"/html/body/div[1]/div[4]/div[3]/div[2]/div[1]/div[4]/div[{i}]/a\")\n",
    "            link = link.get_attribute('href')\n",
    "            url_list.append(link)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        except :\n",
    "            pass\n",
    "\n",
    "    for k in range(len(url_list)):\n",
    "        try :\n",
    "            a = url_list[k]\n",
    "            driver.get(a)\n",
    "            title = driver.find_element(By.CSS_SELECTOR, 'span.JobHeader_companyNameText__uuJyu > a')\n",
    "            job = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[2]/span')\n",
    "            requirements = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[3]/span')\n",
    "            preferential = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[4]/span')\n",
    "            welfare = driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[1]/div[1]/div[1]/div[2]/section[1]/p[5]/span')\n",
    "            # Scrape the technology stack and tools\n",
    "            tech_stack_elements = driver.find_elements(By.CSS_SELECTOR, '.JobDescription_JobDescription_skill_wrapper__9EdFE .SkillItem_SkillItem__E2WtM')\n",
    "            tech_stack = [element.text for element in tech_stack_elements]\n",
    "            technology_stacks.append(', '.join(tech_stack))  # Combine into a single string\n",
    "            \n",
    "            job_names.append(j)\n",
    "            titles.append(title.text)\n",
    "            jobs.append(job.text)\n",
    "            requirements_list.append(requirements.text)\n",
    "            preferentials.append(preferential.text)\n",
    "            welfares.append(welfare.text)\n",
    "        \n",
    "        except : \n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        '직업' : job_names,\n",
    "        '회사명': titles,\n",
    "        '주요업무': jobs,\n",
    "        '자격요건': requirements_list,\n",
    "        '우대사항': preferentials,\n",
    "        '복지': welfares,\n",
    "        '요구 기술':technology_stacks\n",
    "    })\n",
    "\n",
    "    driver.quit()\n",
    "    df.to_json('df_2.json', orient='records', force_ascii=False)\n",
    "\n",
    "# Schedule the scraping function to run daily\n",
    "schedule.every().day.at(\"10:00\").do(scrape_jobs)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)  # wait one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>직업</th>\n",
       "      <th>회사명</th>\n",
       "      <th>주요업무</th>\n",
       "      <th>자격요건</th>\n",
       "      <th>우대사항</th>\n",
       "      <th>복지</th>\n",
       "      <th>기숤</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>넥슨코리아(NEXON)</td>\n",
       "      <td>[합류하시면 이런 일을 할 수 있어요]\\n• 유저의 인게임 행동/패턴 분석에 기반한...</td>\n",
       "      <td>[이런 분을 찾고 있어요]\\n• 프로그래밍 언어를 활용해 데이터를 다루는 데 자신 ...</td>\n",
       "      <td>[이런 경험을 가진 분들은 더 좋아요]\\n• 분석 인사이트를 바탕으로 실행 가능한 ...</td>\n",
       "      <td>• Work &amp; Life Balance 지원을 위한 마일리지/보육 시설/카페테리아/...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>트릿지</td>\n",
       "      <td>이런 역할을 수행합니다:\\n\\n- 시장경제에 대한 깊은 이해와 트릿지만의 고유 데이...</td>\n",
       "      <td>이런 분을 찾습니다:\\n\\n- 관련 분야 전공(통계학, 컴퓨터공학, 산업공학 등) ...</td>\n",
       "      <td>이런 분이면 더 좋습니다:\\n\\n- 관련 분야 석사 이상 학위 소지, 5년 이상 실...</td>\n",
       "      <td>채용 정보\\n\\n제출서류\\n- 이력서\\n- 경력기술서 등 본인 역량을 어필할 수 있...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>인터엑스</td>\n",
       "      <td>[함께하시면 맡게 될 업무입니다!]\\n\\n- 이미지 및 영상 데이터 처리\\n- 제조...</td>\n",
       "      <td>[이런 분이 필요해요!]\\n \\n- 이미지 데이터에 대한 기초 지식이 있으신 분\\n...</td>\n",
       "      <td>[이런 분이면 더욱 좋아요!]\\n\\n- 논문 및 특허 작성 경험이 있으신 분\\n- ...</td>\n",
       "      <td>□ INTERX의 혜택과 복지\\nº 3년 근속 시, 5일 휴가 or 100만원 보너...</td>\n",
       "      <td>Oracle, Python, Docker, PostgreSQL, UML, 백엔드 개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>넥슨코리아(NEXON)</td>\n",
       "      <td>[이러한 업무들을 함께 진행하고 싶습니다]\\n• 게임 및 비즈니스 분석 업무에 필요...</td>\n",
       "      <td>• SQL, Spark, Airflow, Zeppelin, Snowflake 등의 ...</td>\n",
       "      <td>• 게임 도메인에서 DW/DM 개발 및 업무 경험\\n• 최신 기술 동향에 대한 관심...</td>\n",
       "      <td>• Work &amp; Life Balance 지원을 위한 마일리지 / 보육 시설 / 카페...</td>\n",
       "      <td>.NET, Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>인터엑스</td>\n",
       "      <td>[함께하시면 맡게 될 업무입니다!]\\n\\n- 이미지 및 영상 데이터 처리\\n- 제조...</td>\n",
       "      <td>[이런 분이 필요해요!]\\n \\n- 이미지 데이터에 대한 기초 지식이 있으신 분\\n...</td>\n",
       "      <td>[이런 분이면 더욱 좋아요!]\\n\\n- 논문 및 특허 작성 경험이 있으신 분\\n- ...</td>\n",
       "      <td>□ INTERX의 혜택과 복지\\nº 3년 근속 시, 5일 휴가 or 100만원 보너...</td>\n",
       "      <td>Oracle, Python, Docker, PostgreSQL, UML, 백엔드 개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>빌리뷰</td>\n",
       "      <td>- 고객사(SK그룹 계열사) 데이터 분석 프로젝트\\n    - 이러닝 플랫폼 데이터...</td>\n",
       "      <td>- 유관 분야 경력 1년 이상\\n- Python 중급, SQL 초급 이상</td>\n",
       "      <td>- 다양한 업무 영역에 대한 이해와 관심이 높은 분\\n- Docker, Linux,...</td>\n",
       "      <td>- 유연근무제 (코어타임 11-15)\\n- 원격 근무 적극 활용 (주2일)\\n- 신...</td>\n",
       "      <td>Git, Google Cloud Platform, Python, SQL, AWS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>플래티어</td>\n",
       "      <td>• 서비스 개선 및 목표 달성을 위한 실험의 설계/제안 및 결과 분석\\n• 주요 지...</td>\n",
       "      <td>• 관련 경력 2년 이상 (또는 그에 준하는 역량 보유)\\n• SQL, Python...</td>\n",
       "      <td>• 고객 행동 데이터 분석을 통한 서비스 개선 경험 보유\\n• 통계학과, 수학, 데...</td>\n",
       "      <td>• 기본적인 것은 확실하게\\n   - 4대 보험 가입\\n   - 내일 채움 공제 지...</td>\n",
       "      <td>BitBucket, Git, JIRA, Azure, AWS, DevOps, ITIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>브레인커머스</td>\n",
       "      <td>잡플래닛 데이터분석팀은 원활한 프로덕트 설계와 유저 경험을 향상시키기 위한 최적화를...</td>\n",
       "      <td>• 2~5년의 데이터 분석 경험이 있는 분\\n• SQL을 사용해 직접 데이터를 추출...</td>\n",
       "      <td>• 신사업 전략 수립, KPI Setting 관리 및 조직 관리를 경험해보신 분\\n...</td>\n",
       "      <td>- 분 단위 시차 출퇴근제 (오전 7시~ 오전 10시 사이 자율 출퇴근)\\n- 야근...</td>\n",
       "      <td>Python, R, SQL, Amplitude, Braze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>빗썸코리아</td>\n",
       "      <td>• Data Mart 설계 및 DW Data 개발\\n• 활용 관점의 데이터 분석 및...</td>\n",
       "      <td>• 학사 이상의 학력을 보유하신 분\\n• 금융 혹은 대형 플랫폼 데이터 업무 3년 ...</td>\n",
       "      <td>• 웹크롤링 · RESTful API 경험이 있으신 분\\n• 고객 중심 사고 및 데...</td>\n",
       "      <td>[업무에 몰입할 수 있는 환경을 조성합니다.]\\n\\n• 비포괄임금제 | 일한만큼 받...</td>\n",
       "      <td>Confluence, JIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>데이터 분석가</td>\n",
       "      <td>아임웹</td>\n",
       "      <td>• 다양한 사내의 데이터 수요에 대응하여, 목적에 맞는 적절한 측정 지표를 수립하고...</td>\n",
       "      <td>• 이커머스와 SaaS의 주요 지표와 분석 방법론에 대한 높은 이해도 (GMV, M...</td>\n",
       "      <td>• Mixpanel, Amplitude와 같은 PA툴 활용 경험\\n• 데이터 시각화...</td>\n",
       "      <td>업무가 중요한 만큼 아임웹 구성원의 일상도 중요해요.\\n• 오전 7시~11시, 1분...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        직업           회사명                                               주요업무  \\\n",
       "0  데이터 분석가  넥슨코리아(NEXON)  [합류하시면 이런 일을 할 수 있어요]\\n• 유저의 인게임 행동/패턴 분석에 기반한...   \n",
       "1  데이터 분석가           트릿지  이런 역할을 수행합니다:\\n\\n- 시장경제에 대한 깊은 이해와 트릿지만의 고유 데이...   \n",
       "2  데이터 분석가          인터엑스  [함께하시면 맡게 될 업무입니다!]\\n\\n- 이미지 및 영상 데이터 처리\\n- 제조...   \n",
       "3  데이터 분석가  넥슨코리아(NEXON)  [이러한 업무들을 함께 진행하고 싶습니다]\\n• 게임 및 비즈니스 분석 업무에 필요...   \n",
       "4  데이터 분석가          인터엑스  [함께하시면 맡게 될 업무입니다!]\\n\\n- 이미지 및 영상 데이터 처리\\n- 제조...   \n",
       "5  데이터 분석가           빌리뷰  - 고객사(SK그룹 계열사) 데이터 분석 프로젝트\\n    - 이러닝 플랫폼 데이터...   \n",
       "6  데이터 분석가          플래티어  • 서비스 개선 및 목표 달성을 위한 실험의 설계/제안 및 결과 분석\\n• 주요 지...   \n",
       "7  데이터 분석가        브레인커머스  잡플래닛 데이터분석팀은 원활한 프로덕트 설계와 유저 경험을 향상시키기 위한 최적화를...   \n",
       "8  데이터 분석가         빗썸코리아  • Data Mart 설계 및 DW Data 개발\\n• 활용 관점의 데이터 분석 및...   \n",
       "9  데이터 분석가           아임웹  • 다양한 사내의 데이터 수요에 대응하여, 목적에 맞는 적절한 측정 지표를 수립하고...   \n",
       "\n",
       "                                                자격요건  \\\n",
       "0  [이런 분을 찾고 있어요]\\n• 프로그래밍 언어를 활용해 데이터를 다루는 데 자신 ...   \n",
       "1  이런 분을 찾습니다:\\n\\n- 관련 분야 전공(통계학, 컴퓨터공학, 산업공학 등) ...   \n",
       "2  [이런 분이 필요해요!]\\n \\n- 이미지 데이터에 대한 기초 지식이 있으신 분\\n...   \n",
       "3  • SQL, Spark, Airflow, Zeppelin, Snowflake 등의 ...   \n",
       "4  [이런 분이 필요해요!]\\n \\n- 이미지 데이터에 대한 기초 지식이 있으신 분\\n...   \n",
       "5           - 유관 분야 경력 1년 이상\\n- Python 중급, SQL 초급 이상   \n",
       "6  • 관련 경력 2년 이상 (또는 그에 준하는 역량 보유)\\n• SQL, Python...   \n",
       "7  • 2~5년의 데이터 분석 경험이 있는 분\\n• SQL을 사용해 직접 데이터를 추출...   \n",
       "8  • 학사 이상의 학력을 보유하신 분\\n• 금융 혹은 대형 플랫폼 데이터 업무 3년 ...   \n",
       "9  • 이커머스와 SaaS의 주요 지표와 분석 방법론에 대한 높은 이해도 (GMV, M...   \n",
       "\n",
       "                                                우대사항  \\\n",
       "0  [이런 경험을 가진 분들은 더 좋아요]\\n• 분석 인사이트를 바탕으로 실행 가능한 ...   \n",
       "1  이런 분이면 더 좋습니다:\\n\\n- 관련 분야 석사 이상 학위 소지, 5년 이상 실...   \n",
       "2  [이런 분이면 더욱 좋아요!]\\n\\n- 논문 및 특허 작성 경험이 있으신 분\\n- ...   \n",
       "3  • 게임 도메인에서 DW/DM 개발 및 업무 경험\\n• 최신 기술 동향에 대한 관심...   \n",
       "4  [이런 분이면 더욱 좋아요!]\\n\\n- 논문 및 특허 작성 경험이 있으신 분\\n- ...   \n",
       "5  - 다양한 업무 영역에 대한 이해와 관심이 높은 분\\n- Docker, Linux,...   \n",
       "6  • 고객 행동 데이터 분석을 통한 서비스 개선 경험 보유\\n• 통계학과, 수학, 데...   \n",
       "7  • 신사업 전략 수립, KPI Setting 관리 및 조직 관리를 경험해보신 분\\n...   \n",
       "8  • 웹크롤링 · RESTful API 경험이 있으신 분\\n• 고객 중심 사고 및 데...   \n",
       "9  • Mixpanel, Amplitude와 같은 PA툴 활용 경험\\n• 데이터 시각화...   \n",
       "\n",
       "                                                  복지  \\\n",
       "0  • Work & Life Balance 지원을 위한 마일리지/보육 시설/카페테리아/...   \n",
       "1  채용 정보\\n\\n제출서류\\n- 이력서\\n- 경력기술서 등 본인 역량을 어필할 수 있...   \n",
       "2  □ INTERX의 혜택과 복지\\nº 3년 근속 시, 5일 휴가 or 100만원 보너...   \n",
       "3  • Work & Life Balance 지원을 위한 마일리지 / 보육 시설 / 카페...   \n",
       "4  □ INTERX의 혜택과 복지\\nº 3년 근속 시, 5일 휴가 or 100만원 보너...   \n",
       "5  - 유연근무제 (코어타임 11-15)\\n- 원격 근무 적극 활용 (주2일)\\n- 신...   \n",
       "6  • 기본적인 것은 확실하게\\n   - 4대 보험 가입\\n   - 내일 채움 공제 지...   \n",
       "7  - 분 단위 시차 출퇴근제 (오전 7시~ 오전 10시 사이 자율 출퇴근)\\n- 야근...   \n",
       "8  [업무에 몰입할 수 있는 환경을 조성합니다.]\\n\\n• 비포괄임금제 | 일한만큼 받...   \n",
       "9  업무가 중요한 만큼 아임웹 구성원의 일상도 중요해요.\\n• 오전 7시~11시, 1분...   \n",
       "\n",
       "                                                  기숤  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  Oracle, Python, Docker, PostgreSQL, UML, 백엔드 개...  \n",
       "3                                         .NET, Java  \n",
       "4  Oracle, Python, Docker, PostgreSQL, UML, 백엔드 개...  \n",
       "5  Git, Google Cloud Platform, Python, SQL, AWS, ...  \n",
       "6  BitBucket, Git, JIRA, Azure, AWS, DevOps, ITIL...  \n",
       "7                   Python, R, SQL, Amplitude, Braze  \n",
       "8                                   Confluence, JIRA  \n",
       "9                                                     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('df_1.json', orient='records', force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['직업', '회사명', '주요업무', '자격요건', '우대사항', '복지'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('df.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "직업\n",
       "백엔드 개발자       10\n",
       "AI 엔지니어       10\n",
       "데이터 사이언티스트    10\n",
       "앱 개발자         10\n",
       "데이터 분석가        9\n",
       "프론트엔드 개발자      9\n",
       "UI/UX 디자이너     9\n",
       "데이터 엔지니어       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['직업'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
