title,body,image,url
Spring Boot 컨테이너 이미지 사이즈 경량화 방법,스프링 부트 기반으로 개발한 어플리케이션을 컨테이너 이미지로 만들 때 이미지 사이즈를 줄이는 방법에 대해서 알아보자 먼저 sample source 를 다운 받는다 git clone httpsgithubcomseungkyuaspringbootdockergit cd springbootdocker 다운 받은 소스에서 mvn 으로 package 를 빌드한다 mvn package 빌드 후에 소스의 디렉토리 구조는 다음과 같다 tree L 2 LICENSE READMEmd docker Dockerfile Dockerfile2 Dockerfile3 logs accessloglog pomxml scripts runsh src main target classes example001SNAPSHOTjar example001SNAPSHOTjaroriginal generatedsources mavenarchiver mavenstatus work Tomcat 오늘은 자바 소스는 상관없이 도커 이미지 빌드에 대해서만 설명하므로 Dockerfile 만 살펴보자 컨테이너 이미지 만들기 기본편 dockerDockerfile2 을 보면 아래와 같다 FROM openjdk1702jdkslim MAINTAINER Ahn Seungkyu ARG JARFILEexample001SNAPSHOTjar RUN mkdir p app WORKDIR app COPY targetJARFILE appappjar COPY scriptsrunsh ENTRYPOINT runsh base 이미지로 openjdk1702jdkslim 이미지를 사용하였고 target 아래의 빌드된 jar 파일을 복사하여 실행하는 방법이다 실행 명령어는 scriptsrunsh 파일을 보면 알 수 있다 binsh java JAVAOPTS jar appjar JAVAOPTS 는 환경 변수 이므로 컨테이너를 실행할 때 해당 값을 전달하는 것이 가능하다 이제 컨테이너 이미지를 빌드하면 그 사이즈는 다음과 같다 docker build t seungkyuaspringbootdocker f dockerDockerfile2 output Building 26s 1111 FINISHED dockerdesktoplinux internal load build definition from Dockerfile2 00s transferring dockerfile 442B 00s internal load dockerignore 00s transferring context 2B 00s internal load metadata for dockeriolibraryopenjdk1702jdkslim 22s auth libraryopenjdkpull token for registry1dockerio 00s CACHED 15 FROM dockeriolibraryopenjdk1702jdkslimsha256aaa3b3cb27e3e520b8f116863d0580c438ed55ecfa0bc126b41f68c3f62f9774 00s internal load build context 00s transferring context 291B 00s 25 RUN mkdir p app 01s 35 WORKDIR app 00s 45 COPY targetexample001SNAPSHOTjar appappjar 01s 55 COPY scriptsrunsh 00s exporting to image 01s exporting layers 01s writing image sha2566d6ba6764805971eef0532e21ec28feb6308ddb04bb650a7d087ab689d0d65be 00s naming to dockerioseungkyuaspringbootdocker docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE seungkyuaspringbootdocker latest 6d6ba6764805 54 seconds ago 473MB 이미지 크기가 473M 로 만들어졌다 어플리케이션 jar 파일의 크기가 68M 이므로 JVM 을 포함하는 이미지가 405M 의 크기가 된다는 의미이다 보통 이미지를 작게하기 위해서 base 이미지 태그로 alpine 이나 slim 을 많이 사용한다 여기서 slim 을 사용했는데도 이 정도 크기라면 사이즈가 작다고 할 수 없다 더 작은 사이즈를 만들기 위해서 alpine 이미지를 찾아서 적용해 보자 base 이미지를 amazoncorretto 로 변경하고 다시 사이즈를 비교해 보자 FROM amazoncorretto17alpine MAINTAINER Ahn Seungkyu ARG JARFILEexample001SNAPSHOTjar RUN mkdir p app WORKDIR app COPY targetJARFILE appappjar COPY scriptsrunsh ENTRYPOINT runsh docker build t seungkyuaspringbootdocker f dockerDockerfile2 docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE seungkyuaspringbootdocker latest ed08524545ba 31 seconds ago 358MB none none 6d6ba6764805 7 minutes ago 473MB 조회되는 이미지를 보면 base 이미지만을 바꿨을 뿐인데 358M 로 줄어들었다 컨테이너 이미지 만들기 멀티 스테이지 컨테이너 이미지 사이즈를 줄이기 위해서 멀티 스테이지를 써야 한다는 말을 들어봤을 것이다 여기서도 사이즈를 줄이기 위해 멀티 스테이지를 사용해 보자 dockerDockerfile3 를 보면 멀티 스테이지를 어떻게 구성하는지 알 수 있다 syntaxdockerdockerfile1 FROM maven385openjdk17 as build MAINTAINER Ahn Seungkyu WORKDIR app COPY app RUN mounttypecachetargetrootm2 mvn Dmavenwagonhttpsslinsecuretrue Dmavenwagonhttpsslallowalltrue package FROM amazoncorretto17alpine MAINTAINER Ahn Seungkyu ARG JARFILEexample001SNAPSHOTjar WORKDIR app COPY frombuild apptargetJARFILE appappjar COPY scriptsrunsh app ENTRYPOINT runsh 빌드하는 이미지와 런타임에서 실행되는 이미지가 나눠져 있다 syntaxdockerdockerfile1 는 이미지 안에서 소스 빌드를 할 때 디펜던시가 있는 파일을 매번 가져오지 말고 한 번만 가져와서 캐싱하여 효율적으로 사용하고자 할 때 사용한다 mounttypecachetargetrootm2 는 로컬에 저장해서 재활용하자는 의미이고 Dmavenwagonhttpsslinsecuretrue Dmavenwagonhttpsslallowalltrue 메이븐으로 패키지할 때 jvm 이 ssl 인증서 없이 사용하기 위해서 추가되었다 첫번째는 어플리케이션을 빌드하기 위해 필요한 이미지 정의이고 두번째는 빌드된 어플리케이션을 복사하는 이미지 정의로 두번째는 앞서 기본편에서 설명한 것과 동일하다 jar 파일만 빌드해서 복사하는 구조라 실제로 이미지 차이는 없을 것이다 다만 빌드를 이미지를 만들 때 로컬 환경 구성 없이도 만들 수 있다는 장점이 있다 docker build t seungkyuaspringbootdocker f dockerDockerfile3 docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE seungkyuaspringbootdocker latest 33ed3cbf0300 31 seconds ago 358MB none none ed08524545ba 4 minutes ago 358MB none none 6d6ba6764805 7 minutes ago 473MB 컨테이너 이미지 만들기 alpine 에 추가 여전히 사이즈가 358M 로 작지 않은 사이즈이다 이제 기본 alpine 이미지에 JRE 와 어플리케이션을 설치하는 방법으로 이미지 사이즈를 줄여보자 dockerDockerfile 을 살펴보자 FROM amazoncorretto17alpine318 as builderjre RUN apk add nocache repositoryhttpdlcdnalpinelinuxorgalpineedgemain binutils241r0 RUN JAVAHOMEbinjlink modulepath JAVAHOMEjmods verbose addmodules ALLMODULEPATH stripdebug nomanpages noheaderfiles compress2 output jre syntaxdockerdockerfile1 FROM maven385openjdk17 as build MAINTAINER Ahn Seungkyu WORKDIR app COPY app RUN mounttypecachetargetrootm2 mvn Dmavenwagonhttpsslinsecuretrue Dmavenwagonhttpsslallowalltrue package FROM alpine3184 MAINTAINER Ahn Seungkyu ENV JAVAHOMEjre ENV PATHJAVAHOMEbinPATH ARG JARFILEexample001SNAPSHOTjar COPY frombuilderjre jre JAVAHOME ARG APPLICATIONUSERappuser RUN adduser nocreatehome u 1000 D APPLICATIONUSER RUN mkdir app chown R APPLICATIONUSER app USER 1000 COPY chown10001000 frombuild apptargetJARFILE appappjar COPY scriptsrunsh app WORKDIR app EXPOSE 8080 ENTRYPOINT runsh 이미지가 3개로 구성되어 있다 첫번째는 작은 사이즈의 jre 를 만드는 이미지 두번째는 어플리케이션을 빌드하는 이미지 마지막으로 세번째는 작은 alpine 베이스 이미지에 jre 와 빌드된 어플리케이션 jar 파일을 복사하는 이미지이다 첫번째 이미지 만드는 부분에서 binutils 을 설치하는데 다운 받을 리파지토리를 지정하여 에러가 없게 한다 binutils 는 jre 을 만들 때 stripdebug 옵션을 사용하기 위해서 설치한다 세번째 이미지 만드는 부분에서 사용자를 추가하는 로직이 있는데 이는 보안상 이미지내 실행 프로세스를 root 가 아닌 지정된 사용자로 하기 위해서 일반적으로 추가한다 이미지 사이즈는 다음과 같다 docker build t seungkyuaspringbootdocker f dockerDockerfile docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE seungkyuaspringbootdocker latest f5dc2f994864 28 seconds ago 168MB none none ed08524545ba 24 minutes ago 358MB none none 6d6ba6764805 31 minutes ago 473MB 이미지가 최종적으로 168M 로 줄어들었다 이제 실제 이미지가 정상적으로 실행되는지 확인해 보자 mysql 을 띄우고 어플리케이션을 띄운 후에 curl 로 데이터를 입력해 본다 1 mysql 실행 mkdir p dockerdatamysql docker run capaddsysnice d restartalways p 33063306 e MYSQLROOTPASSWORDpassword v dockerdatamysqlvarlibmysql name mysqlask mysql8034 charactersetserverutf8mb4 collationserverutf8mb4unicodeci 2 database 생성 docker exec it mysqlask bash mysql uroot ppassword mysql create database if not exists orderservice 3 어플리케이션 실행 docker run d name springboot rm p 1909019090 link mysqlasklocalhost seungkyuaspringbootdocker 4 데이터 조회 curl X POST http12700119090orders H ContentType applicationjson d customerId 1 orderTotal 1223 output orderId1 정상적으로 어플리케이션이 실행되어 동작하는 것을 확인할 수 있다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=165369&boardType=techBlog&searchData=&page=&subIndex=
ArgoCD + AWS EKS + CodeCommmit + CodeBuild 로 CI/CD 구축하기,1 AWS IAM 준비 AWS User를 두 개 생성해야 한다 1 admin 전체적인 흐름을 담당할 유저를 admin 이라는 이름으로 만들었다 httpscataloguseast1prodworkshopsawsworkshops9c0aa9ab90a944a6abe18dff360ae428koKR20preq100account 위 링크대로 진행해 사용자를 만들어 로그인 후 AWS IAM페이지 좌측 액세스 관리 메뉴 사용자 admin 보안 자격 증명 액세스 키를 만든다 2 ekscicdargo ArgoCD가 레포지토리를 모니터링하고 클러스터에 적용하는 데에 필요한 유저를 만든다 httpscataloguseast1prodworkshopsawsworkshops9c0aa9ab90a944a6abe18dff360ae428koKR110cicd110cicd 위 링크의 6 ArgoCD 설정 부분을 참조해 진행하고 Credentials을 다운받는 것까지 해둔다 2장비 준비 EKS를 생성해야 한다 그러기 위해서 bastion server용도로 EC2를 하나 준비해보자 1 EC2 준비 EKS 구성을 위한 커맨드 타이핑작업은 다 이 EC2에서 이루어질 예정이다 직접 콘솔에서 만들어도 되지만 terraform을 이용해 AWS세팅을 마쳤다 테라폼을 한 번 써보고 싶어서 굳이 써봤다 클릭노가다에서 해방될뿐만 아니라 뭔가 잘못됐을 때 곧바로 밀어버리기도 너무나 편해서 감격했다 아래의 링크를 참조해 진행했다 기초 튜토리얼임에도 이번 셋팅에 아무런 부족함이 없었다 httpswww44bitsiokopostterraformintroductioninfrastrucuteascode provider설정이 누군가에게 도움이 될 것 같아 남겨본다 튜토리얼 그대로 진행하되 AMI를 최신화했고 resource 이름을 bastion으로 변경했다 resource awskeypair webadmin keyname webadmin publickey filesshwebadminpub resource awssecuritygroup ssh name allowsshfromall description Allow SSH port from all ingress fromport 22 toport 22 protocol tcp cidrblocks 00000 data awssecuritygroup default name default resource awsinstance bastion ami ami05548f9cecf47b442 aws 2023 instancetype t3small keyname awskeypairwebadminkeyname vpcsecuritygroupids awssecuritygroupsshid dataawssecuritygroupdefaultid 잘 만들어진 EC2의 public ip를 확인하고 접속한다 terraform console awsinstancebastionpublicip 확인한 퍼블릭 ip exit ssh i sshwebadmin ec2user확인한 퍼블릭 ip 2 EKS 시작 서버에 들어간 이후부터는 아래의 링크를 참조해 EKS를 설정했다 httpsdevoceanskcomblogtechBoardDetaildoID163654 3 ArgoCD 설치 서버에 들어간 채로 아래의 명령어를 넣어 ArgoCD 설치과정을 마친다 kubectl create namespace argocd kubectl apply n argocd f httpsrawgithubusercontentcomargoprojargocdstablemanifestshainstallyaml kubectl patch svc argocdserver n argocd p spec type LoadBalancer 이 이후의 자잘한 세부 설정과 실제 엔드포인트 확인방법은 httpsdevoceanskcomblogtechBoardDetaildoID163661 를 참조했다 ArgoCD에 대한 자세한 이해는 httpsdevoceanskcomblogtechBoardDetaildoID164752boardTypetechBlognone 링크를 참조했다 4 Repository 만들기Git ECR 1 git repository 만들기 하나의 서비스가 있을 때 레포지토리는 두 개 필요하다 소스 저장용 Repo GitOps용 Repo 소스 저장용 Repo가 저장하는 것들 개발자의 피땀어린 소스코드 Dockerfile buildspecyaml 이 파일대로 CodeBuild가 동작한다 GitOps용 Repo가 저장하는 것들 deploymentyaml 이 파일 안에 이미지 태그가 있다 serviceyaml 2 AWS ECR repository 만들기 배포의 개념이 소스코드를 냅다 데몬으로 돌리는 게 아니라 이제 이미지 단위로 apply하는 개념으로 바뀐다 AWS ECR에 repository를 하나 만든다 5 AWS CodePipeline 만들기 AWS에서의 흐름은 다음과 같다 개발자가 본인의 소스코드를 소스 레포에 push 한다 CodePipeline이 소스 레포를 지켜보고 있다 그걸 감지하고 CodeBuild를 트리거한다 31 CodeBuild는 buildspec 파일대로 컨테이너 이미지를 만들고 ECR에 푸시한다 32 이미지 푸시에 문제가 없다면 깃옵스 레포를 clone해온 뒤 deployment 파일 안의 이미지 태그만 변경해서 커밋한다 ArgoCD는 깃옵스 레포를 지켜보고 있다 깃옵스 레포가 업데이트되면새 이미지가 생기면 그걸 가져와서 EKS에 kubectl apply한다 파이프라인 구성은 httpsmay9noytistorycom706 여기를 참조하는데 buildspec파일은 아래 코드대로 작성했다 version 02 env shell bash phases install runtimeversions docker 20 commands curl o kubectl httpsamazonekss3uswest2amazonawscom119620210105binlinuxamd64kubectl chmod x kubectl mv kubectl usrlocalbinkubectl mkdir kube aws eks updatekubeconfig region useast1 name eksdemo git config global credentialhelper aws codecommit credentialhelper git config global credentialUseHttpPath true prebuild commands echo Logging in to Amazon ECR aws ecr getloginpassword region AWSDEFAULTREGION docker login username AWS passwordstdin AWSACCOUNTIDdkrecrAWSDEFAULTREGIONamazonawscom build commands echo Building the Docker image DATEdate Ymd docker build t IMAGEREPONAMEIMAGETAGDATE docker tag IMAGEREPONAMEIMAGETAGDATE AWSACCOUNTIDdkrecrAWSDEFAULTREGIONamazonawscomIMAGEREPONAMEIMAGETAGDATE docker push AWSACCOUNTIDdkrecrAWSDEFAULTREGIONamazonawscomIMAGEREPONAMEIMAGETAGDATE postbuild commands AWSECRURIAWSACCOUNTIDdkrecrAWSDEFAULTREGIONamazonawscomIMAGEREPONAMEIMAGETAGDATE echo Build completed on DATE aws configure set accesskey CODECOMMITACCESSKEY aws configure set secretkey CODECOMMITSECRETKEY git clone httpsgitcodecommitAWSDEFAULTREGIONamazonawscomv1reposOPSREPONAME cd OPSREPONAME sed simage image AWSACCOUNTIDdkrecrAWSDEFAULTREGIONamazonawscomIMAGEREPONAMEIMAGETAGDATE deploymentyaml tmpfile mv tmpfile deploymentyaml git config global useremail GITUSEREMAIL git config global username GITUSERNAME git add git commit m update image tag DATE git push 6 ArgoCD와 깃옵스 레포 연결하기 ArgoCD가 깃옵스 레포를 보고 있을 수 있도록 설정한다 이 내용은 httpsawsdiarytistorycom52 여기를 참조했다 3분에 한 번 가져오는 게 기본값인데 CodeBuild에서 웹훅을 던질 수도 있다고 한다 일단은 수동 sync로 정책을 잡고 연결했다 이제 개발자가 소스 레포에 푸시를 할 때마다 새로운 레플리카셋이 생기고 문제가 없다면 파드가 생긴다 위 사진은 시행착오를 겪는 동안 생긴 쓰레기 레플리카셋이 즐비한 모습이다 다음은 여기에 쿠버네티스 관리정책을 붙여야 하고 grafana prometheus를 붙이고 테스트 자동화도 붙여야 한다 argo rollout을 연동하는 것도 고려해봐야 한다 일을 하나 끝냈는데 열 가지 일이 생겼다 TMI 글을 써 보니 알겠다 인터넷에 올라온 수많은 포스트들이 파편화되어 있었고 오묘한 개발센스가 필요한 영역이 많아서 구현이 너무 어려웠는데 어찌어찌 구현은 했으나 글로 쓰려니까 잘 쓰기가 쉽지 않다 이 글도 빠른 시일 내에 자세히 업데이트할 예정이다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=165211&boardType=techBlog&searchData=&page=&subIndex=
데보션 전문가를 만나다 12) 대학생이 만난 데보션 전문가 6편,안녕하세요 저희는 데보션 영 1기 복불복 조입니다 저희는 데보션 전문가이신 Ssunny님과 인터뷰를 가졌습니다 SSunny라는 이름처럼 햇살 같은 웃음을 선사해주신 SSunny님 과의 인터뷰를 이곳에 요약했으니 재밌게 봐주세요 참고로 SSunny님은 SKT A추진단에 계신데 A추진단에서 만든 에이닷의 사진 마스크기능을 활용해서 사진을 편집해보았습니다 인터뷰 내용 Q1 현재 맡고 계신 직무에 대한 소개 부탁드리겠습니다 볼보 차량에서 동작하는 아리아에 대한 소프트웨어 품질 보증 업무를 담당하고 있습니다 Q2 QA란 무엇인가요 Quality Assurance의 약자로 소프트웨어 요구 사항 분석 시점부터 참여해서 요구 사항 및 사용자 관점 테스트를 만들고 소프트웨어가 사용자에게 닿는 전반적인 과정프로세스을 관리해 소프트웨어의 품질을 높이는 업무입니다 Q3 소프트웨어 품질 보증할 때 테스트의 제작 기준이 있으신가요 통상적으로 요구사항을 만드는 입장에서 원하는 스펙이 있는데 대상이 일반인이기 때문에 그 눈높이에 맞춰서 수준을 매우 낮춥니다 사용자들이 불편해 하실 사항까지도 이슈로 두고 테스트 케이스를 만듭니다 제품에 따라 b2b인 경우 혹은 b2g인 경우 정부 기관이나 업체에서 원하는 규정에 맞춥니다 정부 같은 경우 법 준수가 중요하고 사내 규정도 있기 때문에 잘 맞추어서 만들게 됩니다 프로세스가 굉장히 구체적으로 구성되어 있습니다 Q4 새로운 품질보증 평가기준을 만들 때 기존 인증 체계에서 얼마나 많이 참고하고 신뢰할만한 혹은 근거가 없는 새로운 기준의 경우 신뢰성을 어떻게 얻나요 지금 작업하고 있는 볼보 차량 소프트웨어에 대한 음성인식 기능이 그러한 경우라고 할 수 있을 거 같습니다 테스트의 명확한 기준이 잡혀 있지 않아 팀원 서로가 막막한 상황이었습니다 그래서 요구사항을 스토리로 나눠서 스토리별로 테스트 케이스별로 촘촘하게 짜서 통과율을 구하고 이것을 기준으로 6070 차근차근 목표를 만들어 나갔습니다 최종적으로 고객에게 보여드릴 때는 95이 되도록 기준을 잡았습니다 부가적으로 이슈 처리율도 있는데 이슈를 수정했을 때 수정됐는지 확인하는 것입니다 이슈 처리율도 90이상이어야 한다는 내부 기준도 만들었습니다 극단적으로 일반 대중에 대한 서비스의 경우 기능에 대한 이슈 개수에 대한 기준을 두었습니다 시리즈별로 통과 기준을 회사마다 다르게 각각 세우고 있습니다 Q5 기능성 신뢰성 사용성 효율성 유지보수성 이식성 중 제품 특성을 고려해 우선순위를 따지는데 우선순위를 따지기 힘든 경우는 어떻게 문제를 해결하시나요 기능성 같은 경우는 고객의 요구가 반영되기 때문에 최우선적으로 생각하고 나머지도 테스트를 늘려가며 하나씩 해결합니다 예를 들어 이식성의 경우 특정 플랫폼에서만 동작하는 테스트 환경을 줄이고 다양한 플랫폼에서 동작해야 한다면 테스트할 때 다양한 테스트 환경을 엄청 넓게 잡는 등으로 해결합니다 Q6 테스트 검증할 때 발생하는 EdgeCase 에러는 어떻게 핸들링 하시나요 마감 기간까지 발생하는 에러들은 크리티컬 하지 않다면 기록만 해둔 채 릴리즈 한 다음 나중에 수정을 하고 크리티컬 하다면 릴리즈 날짜를 변경해서라도 수정합니다 Q7 SKT에서 사용하는 품질 보증은 어떤 게 있고 자동화 테스트 및 환경은 소프트웨어 상에서만 이뤄지는 건가요 주로 소프트웨어 QA를 진행하는데 Open soruce나 보안성 테스트 등을 주로 사용하며 Appium이나 Selenium 같은 툴을 이용해서 테스트를 진행합니다 Q8 품질에 대한 테스트를 위해서는 협업할 일이 많으실 듯한데 협업을 할 때 가장 중요하게 생각하는 것은 무엇인가요 저희는 JIRA 시스템을 이용해 커뮤니케이션하는데 이 시스템의 티켓 기능을 잘 활용하는 게 중요합니다 티켓을 이용해 히스토리를 남겨 누구든 언제든 어디서든 확인할 수 있어야 협업이 원만하게 진행될 수 있습니다 Q9 지금 하는 일에서 가장 뿌듯했던 경험은 무엇인가요 선임 연구원이 된 지 얼마 안 되었을 때 처음으로 맡았던 빅프로젝트가 공공기관과의 프로젝트였고 릴리즈 한 뒤에는 기사도 여럿 나왔을 정도의 규모가 컸는데 세상에 없던 완전 새로운 프로젝트라서 이슈도 많이 발생해서 힘이 많이 들었어요 그걸 성공적으로 마무리하니까 매우 뿌듯했고 그 뒤로는 어떤 프로젝트를 맡아도 부담이 덜하더라고요 Q10 시니어 개발자인 지금 학생 시절을 돌이켜 봤을 때 학생들이 어떤 것을 하면 좋겠다고 생각 드시나요 저는 호기심이 생기면 전부 해보는 성격이라서 여러 경험들을 쌓아 왔고 이 덕분에 지금까지도 일을 하고 있는 것 같습니다 소프트웨어 QA의 전문가가 되기 위해 기술사 자격증도 따고 책도 내보고 새로운 기술 스터디도 하는 등의 도전을 이어나갔기 때문에 지금의 제가 있다고 생각합니다 따라서 할까 말까를 고민하지말고 도전하는게 중요한 것 같아요 Q11 곧 5년을 채우시고 리프레쉬 휴가를 어떻게 사용할 에정이신가요 주변 동료 중에 50대이신 분이 부모님과 유럽 여행을 가고 싶다고 유럽을 같이 못 간 부모님께 죄스럽다고 하는 분이 계셨습니다 그래서 저도 한번 부모님과 유럽에 가보려구요 Q12 인생에 힘든 순간은 찾아오기 마련인데 sunny님만의 힘든 순간을 극복하는 방법이 있으신가요 저는 메모하는 습관이 있어요 하루하루를 기록하는데 문장을 쓰기보다 마인드맵을 그리듯이 나열합니다 그런걸 10분 20분 하다가 또 예능을 봐요 옛날 예능을 찾아보고 또 지금 같은 출연자가 나오는 예능을 보면서 옛날에 긴장하고 떨리던 사람도 시간이 지나면 저렇게 여유롭고 mc와 노닥이는 걸 봅니다 그러면 나도 시간이 지나면 저렇게 될 수 있겠지 하고 위로해요 강연이나 멘토링에서도 비슷한 질문을 많이 받는데 어차피 도망은 못 가는데 이 순간을 해결하는건 나다 배우는 상황으로 생각하자라고 느끼고 배우면서 성장할 수 있습니다 고민은 10분정도만 하고 또 예능을 다시 보고 내일 또 생각나면 다시 비슷하게 하면서 나아지는 것 같아요 Q13 앞으로 계속 일하시면서 개발 코딩 이외에 배우고 계신거나 해보고 싶으신 취미가 있으신가요 저는 취미가 레고입니다 지금도 배송이 오고 있는데 건물을 좋아하고 레고도 건물 모양으로 많이 모아요 여러 개 레고를 합쳐서 하나의 건물로 만드는 것도 좋아합니다 제가 전에 판교에서 일하면서 주변에 건물이 지어지는 과정을 보니 재밌더라구요 성향이 그런 걸 좋아하는가봐요 Q14 SK가 복지 좋기로 유명한데 sunny님이 하나 추가할 수 있다면 어떤 걸 추가하고 싶으신가요 복지가 굉장히 많아서 간단한 것들은 대부분 있는데 식당 밥을 공짜로 하는 것 저는 자동차쪽으로 프로젝트를 하다 보내 회사에 가면 매일 뭘 먹어야할지 고민하고 혼자 밥먹고 그런게 있어서 밥 먹는게 생각이 많이 나네요 Q15 마지막으로 하고 싶은 말 있으신가요 학생들을 만나면 하고싶은 말이 재지말고 내가 갈 수 있는 동아리나 시험이나 공모전이나 해커톤이나 뭐든지간에 경험을 해보라고 합니다 지금 내가 뭘 하고 싶은지 잘 모르고 성향이 뭔지 모르기 때문에 일단 해보고 그러면서 나의 스토리를 만들어나가면 좋겠다고 생각합니다 내가 하고싶었던 분야 이야기를 만들 때 억지로 만들수는 없죠 계획이 있다면 훨씬 잘 만들어낼 수 있을 것 같아요 마무리 하며 SSunny님과 인터뷰를 하며 이런 내용이 있었습니다 생각하지 말고 일단 해봐요 저희 어머니도 매일 하시는 말씀인데 저는 그 말을 왜 이렇게 안 듣는지 반성하게 되었습니다 마지막으로 인터뷰에 참여해주신 Ssunny님과 인터뷰를 위해 수고한 우리 복불복 팀 너무 감사합니다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=164389&boardType=techBlog&searchData=&page=&subIndex=
KCC 2023 후기 (1) 학회 스케치와 참여 소감,안녕하세요 카카오 광고추천팀 eric신호석입니다 저는 현재 카카오 광고추천팀 내 메시지광고추천플랫폼셀에서 개발 및 운영을 담당하고 있습니다 저는 이번에 한국컴퓨터종합학술대회 Korea Computer Congress KCC 2023에 발표 및 세션 참석을 하게 되었습니다 KCC는 한국정보과학회가 주관하는 매년 열리는 학술 대회입니다 KCC는 한국을 대표하는 컴퓨터 과학 관련 학회로서 학문적인 연구와 지식 교류를 촉진하고 전문가들의 협력을 도모하기 위해 설립되었습니다 한국컴퓨터종합학술대회는 컴퓨터 과학 및 정보 기술 분야에서 활동하는 연구자 학자 기업 연구원 등이 모여 최신 연구 결과 및 기술 동향을 공유하고 이야기할 수 있는 자리를 제공합니다 이 대회는 주제별 세션 튜토리얼 초청 연설 포스터 세션 등 다양한 형태의 프로그램으로 구성되어 있습니다 많은 카카오 개발자들과 함께 이번 KCC 2023에 참여했습니다 KCC 2023은 제주도에 있는 라마다프라자제주호텔과 제주오리엔탈호텔에서 진행되었습니다 저는 KCC 2023을 처음 방문하였습니다 먼저 다양한 논문 발표와 워크숍들이 있는 것에 놀랐습니다 제주도에 많은 분들이 방문하여 여러 정보들과 의견들을 교류하고 있는 모습이 인상 깊었습니다두 번째는 생각에 닿지 않았던 다양한 주제들이 있다는 것을 알았습니다 범죄 수사와 AI 워크숍이나 사회성을 갖고 인간과 교감하는 멀티모달 인터랙션 인공지능 기술개발 과제 총괄 워크숍과 같은 주제들이 해당됩니다 첫 번째로 초거대 언어모델과 자연어처리 워크샵에 참여하였습니다 1시부터 6시까지 진행된 분량이기 때문에 전체 내용을 적을 수는 없지만 최근 트렌드가 되고 있는 ChatGPT에 대한 소개와 ChatGPT3가 가지고 있는 문제점 ChatGPT4에서는 어떻게 개선되었는지 ChatGPT가 못하는 것들에 대한 내용들을 들을 수 있었습니다 또한 기존 언어모델들이 가지고 있는 강점에 대해서도 소개했으며 이를 활용하는 방안에 대해서도 들을 수 있었습니다 그 이외에도 ChatGPT와 같은 언어모델이 가지고 있는 수학적 능력에 관한 연구동향 소개 또한 흥미로웠습니다 컴퓨터 그래픽스 및 상호작용은 교수님이 발표하는 내용이 아닌 대학원생분들이 연구하여 학술발표에서 발표한 내용을 다시 발표하는 내용이었습니다 개발적 관점으로부터 벗어난 HCI와 같은 주제를 포함해 다양한 관점을 볼 수 있었습니다 자폐 환자들을 위한 데일리 루틴 앱 사용자마다 최적화된 수면 계획 시스템이 포함됩니다 또한 뉴스의 정치적 성향을 분석하는 시도나 뉴스 추천 시스템 또한 재미있었습니다 발표자로서 참여한 카카오테크 워크숍은 1시부터 4시까지 진행되었습니다 저는 cookieshake와 함께 큐라스 메시지 광고 추천 플랫폼을 발표하였으며 이를 위해 hendopark jayleneshin liamkim 와 함께 발표를 준비하였습니다 업무를 진행하며 발표 준비를 하다 보니 시간은 절대적으로 부족했지만 틈틈이 스크립트도 준비하며 연습할 수 있었습니다 저희가 준비한 발표의 자세한 내용은 별도의 글로 소개드릴 수 있도록 해보겠습니다발표 당일 청자들은 대학원생분들이 많았습니다 많은 분들이 참석하셔서 발표 내용을 듣고 궁금한 점에 대해서는 구두나 오픈채팅방을 통해서 질문을 하였습니다 여러 세션들 중에서 카카오테크 워크숍에 참여하여 발표를 듣고 질문하는 모습에서 많은 감동을 받았습니다 처음 참여한 KCC 2023이었지만 많은 인상과 경험을 얻게 되어 매우 기쁩니다 이번 학회를 통해 다양한 분야의 논문 발표와 워크숍을 접할 수 있어서 매우 유익했습니다 KCC 2023에 참여하면서 컴퓨터 과학과 정보 기술 분야의 최신 동향을 알게 되었으며 다양한 분들의 의견 또한 볼 수 있었습니다 그런 관점에서 KCC 2023은 지식 교류를 촉진하는 훌륭한 플랫폼이었다고 생각합니다 다음 기회에도 KCC 2024에서 발표할 수 있었으면 좋겠습니다 한국정보과학회 2023 프로그램북 PBpdf kiiseorkr KCC 2023 후기 1 학회 스케치와 참여 소감 현재 글KCC 2023 후기 2 카카오 크루들과 함께 Connect with Kakao Tech,https://tech.kakao.com/storage/2022/02/kakao-tech-logo-1-e1649831117387.png,https://tech.kakao.com/2023/07/05/kcc2023-review-1/
@ITSUB,그래서 올려요 말아요? 역대급 큰 삼성 갤럭시의 판올림 ONE UI 6.0 달라진 7가지,https://img.youtube.com/vi/w1T7SEH1f4I/0.jpg,https://www.youtube.com/watch?v=w1T7SEH1f4I
@nomadcoders,최악의 바이러스를 막고 감옥? 레전드 해커의 이야기!,https://img.youtube.com/vi/Pa_dh9S6Zds/0.jpg,https://www.youtube.com/watch?v=Pa_dh9S6Zds
@codingapple,요즘 개발자 연봉 현실 (2023 stackoverflow 조사),https://img.youtube.com/vi/IoV_94hr7ks/0.jpg,https://www.youtube.com/watch?v=IoV_94hr7ks
"SKT, CES2024서 일상 바꾸는 AI 기술 공개","CES 2024 SK그룹 전시관에서 UAM을 형상화 한 '매직 카펫'에 탑승해 SK텔레콤의 AI 기반 친환경 미래교통체계를 체험하는 모습.
SK텔레콤이 지난 11월 검증에 성공한 액침냉각 기술과 SK브로드밴드 AI 기반 데이터센터 인프라 관리(DCIM) 노하우 등 SK그룹 데이터센터 관련 기술을 풀 스택(Full stack)으로 제공하는 고효율 차세대 AI DC(데이터센터) 모델도 이번 데모룸에서 만나볼 수 있다.",https://imgnews.pstatic.net/image/031/2024/01/09/0000803095_001_20240109092302819.jpg?type=w647,https://n.news.naver.com/mnews/article/031/0000803095?sid=105
@coohde,Next.js 13 - 2. 샘플앱 세탁,https://img.youtube.com/vi/siBQ-y84ZO0/0.jpg,https://www.youtube.com/watch?v=siBQ-y84ZO0
@jocoding,AI 클론싱어 정답 오류 정말 죄송합니다,https://img.youtube.com/vi/H7WnQ5m6xf8/0.jpg,https://www.youtube.com/watch?v=H7WnQ5m6xf8
파이썬과 러스트,안녕하세요 추천팀 제이입니다 저는 팀 내 프로젝트에 새롭게 러스트Rust를 도입하는 과정에서 동일한 애플리케이션을 파이썬Python과 러스트로 각각 개발하여 비교 및 분석하는 과정을 경험했습니다 이 경험을 토대로 실무적 관점에서 파이썬과 러스트의 차이점을 말씀드리고 러스트 도입 시 개발자들이 고려하면 좋을 부분들을 공유하겠습니다 개발 배경 저희 추천팀에서는 기존의 머신러닝 플랫폼을 대체할 새로운 플랫폼 개발을 진행하고 있었습니다 저희가 고려하고 있던 이 플랫폼의 기능 중에는 사용자 지표 정보를 처리하는 애플리케이션이 있었는데요 클릭 수 클릭률 노출한 상품의 다양성과 같은 사용자 지표를 종합하고 지표들의 분석을 도와주는 기능을 구현하고자 했습니다세부적으로는 이 애플리케이션을 사용하기 위해서 관리자가 어떤 데이터로 어떤 사용자 지표를 만들지 명시하면 해당 내용을 바탕으로 개별 사용자 피드백이 필터 변형 분류 집합 과정을 거쳐 최종 사용자 지표로 계산되는 것을 구상했었습니다 즉 개발 중이던 애플리케이션의 주된 임무는 명시된 내용을 해석하고 그에 맞는 데이터 조작 알고리즘을 수행하는 것이라고 할 수 있습니다 해당 애플리케이션은 현재 외부 자원으로 카프카와 몽고 DB를 사용하고 외부에서 조회를 응답하기 위한 웹 API가 구현되어 있습니다 애플리케이션 개발을 시작하던 당시 저희 팀은 러스트 도입을 고민하고 있었습니다 팀 내 주력 언어인 파이썬으로 애플리케이션의 성능과 안전성을 모두 챙기기에는 조금 힘든 부분이 있어 상대적으로 이 부분에 강점이 있다는 러스트를 주목했습니다 또한 아마존 페이스북 구글 등의 빅테크 기업에서 러스트를 적극적으로 활용하고 러스트 도입 성공 사례가 늘어나면서 러스트 언어의 신뢰도가 점차 높아지는 상황이었습니다이러한 상황에서 최종적으로 러스트 도입하기 위해서는 내부적으로 서비스 영향이 작은 애플리케이션을 성공적으로 러스트로 전환해 보며 그 가능성을 판단해 보는 시도가 남았었습니다 그래서 사용자 지표 애플리케이션에 러스트를 도입하여 러스트로 애플리케이션을 구현하는 것이 적절한지 검증하는 절차를 진행하게 되었습니다 더 많은 기업의 러스트 도입 사례는 rustcompanies를 참고해 주세요 지표 애플리케이션에 러스트를 도입하기 위해 처음 개발은 핵심 기능을 포함하는 프로토타입을 파이썬으로 구현하였고 이 애플리케이션을 다시 러스트로 작성해 두 가지 버전의 애플리케이션을 완성했습니다 이제 본격적으로 러스트 전환 과정에서 느낀 점과 두 결과물의 비교를 몇 가지 키워드로 갈무리해 보겠습니다 성능 먼저 두 결과물의 성능을 비교해 보겠습니다 저희 팀이 러스트를 도입하는 가장 큰 이유 중 하나가 성능이기 때문입니다먼저 언급드리고 싶은 점은 어떠한 성능 파라미터에 관심을 두는지에 따라 두 개발 언어의 성능 비교에 큰 차이가 있다는 것입니다 이 글에서 언급된 성능 수치는 참고만 하시는 것을 추천드리며 실제 값은 애플리케이션을 직접 작성해 비교해 주시기 바랍니다애플리케이션은 크게 카프카Kafka 메시지로 유입되는 사용자 피드백에서 데이터를 추출해 수집하는 수집 모듈과 웹 API로 요청된 사용자 쿼리를 해석해 사용자 지표를 실시간으로 계산해 응답하는 쿼리 모듈로 나뉩니다 성능 비교는 더 중요하다고 생각하는 수집 모듈을 기준으로 진행했습니다 파이썬으로 작성된 결과물은 이 작업에서 파이썬 310 버전 confluentkafka orjson motor를 사용합니다러스트로 작성된 결과물은 이 작업에서 러스트 167 버전 serdejson rdkafka mongodb를 사용합니다 다음은 카프카 메시지 50건을 소비 데이터 변형 몽고 DB에 저장하는 작업의 시간Elapsed time과 메모리 사용량입니다 위의 표를 참조하면 러스트가 파이썬보다 작업을 19배 정도 빠르게 처리한 것을 알 수 있습니다 또한 메모리 사용량은 파이썬이 러스트 보다 45배 정도 더 사용했습니다 마지막으로 표에는 없지만 파이썬의 CPU 사용량은 러스트보다 최대 3배 평균 2배 정도 높았습니다결과적으로 같은 조건에서 러스트 결과물이 파이썬 결과물보다 메시지 처리량과 처리 속도가 높다고 할 수 있습니다 구현한 애플리케이션은 클라우드에 배포되어 카프카Kafka 메시지 유입량에 따라 수평 확장Scale out을 하므로 이와 같은 성능 차이는 전체 운영 비용이 절감되는 효과를 가집니다당연하지만 다양한 방식의 최적화를 통해 두 결과물의 차이를 줄이거나 더 벌릴 수 있을 것입니다 실제로 파이썬의 asyncio와 러스트의 tokio가 각 언어의 애플리케이션에 적용되어 비동기 처리가 동일하게 구현된 단일 스레드 환경에서도 러스트의 메시지 처리 속도가 파이썬 보다 10배 정도 빨랐습니다 아마도 파이썬의 경우에 이미 적용한 confluentkafka 라이브러리 대신 비동기를 지원하면서 성능이 더 좋은 파이썬 카프카 라이브러리를 사용하면 다시 둘 간의 성능 차이는 줄어들 것입니다 하지만 레퍼런스를 참조하기 쉽고 라이선스 문제가 없는 라이브러리를 찾지 못해 아쉽게도 라이브러리를 교체하지 못했습니다 파이썬과 러스트의 구체적인 성능 비교가 궁금하신 분들은 Web Frame Benchmarks Python Rust와 programminglanguagebenchmarks pythonvsrust를 참고해 주세요 CPU 사용량을 봤을 때 두 언어에서 성능 차이의 대부분은 입출력Input Output 이하 IO 작업인 카프카 메시지 소비 작업과 몽고 DB 도큐먼트 저장 작업에서 비롯된 것이었습니다 그리고 두 작업은 전적으로 애플리케이션 구현 시 사용하는 라이브러리가 결정합니다 이러한 라이브러리에 종속적인 전체 작업 시간의 관점에서 볼 때 러스트 언어의 고성능 라이브러리를 사용하면 적은 노력으로도 파이썬 대비 높은 성능을 꾀할 수 있을 것으로 생각했습니다 학습 비용 러스트의 큰 단점 중 하나는 학습 비용이 많이 든다는 것입니다 소유권 수명 같은 생소한 개념과 열거형 매크로 및 트레이트 같은 기능을 모두 학습해야 구현이 가능하기 때문입니다 그에 반해 파이썬은 문법이 쉽고 간결하며 프로그래밍 언어를 모르는 사람도 금방 배우기 좋은 언어입니다 보통 하나의 언어에 능통하다면 다른 언어를 쉽게 익히는 편이지만 파이썬과 러스트는 컴파일 메모리 관리 그리고 동적정적 타입까지 서로 다른 확연한 차이점 때문에 파이썬에 능숙하더라도 러스트에 익숙해지는 데 상당한 시간이 필요합니다이와 같은 높은 학습 비용은 개발 비용을 수직 상승하게 하는 주범일 수 있습니다 러스트를 잘 다루는 개발자를 구하기 힘들 수 있고 구현 이후에도 팀의 소수 인원이 애플리케이션을 유지보수할 가능성이 높으며 상황이 여의치 않을 때는 학습 시간을 작업 시간에 온전히 포함해야 하는 경우도 있기 때문입니다 생산성 파이썬은 애플리케이션을 빠르게 구현해서 프로토타입을 통해 구현 가능성을 증명하는 데 장점이 있습니다 언어의 문법이 쉬우며 다양한 레퍼런스가 있고 관련 패키지만 설치되어 있으면 어느 플랫폼에서도 테스트할 수 있기 때문입니다 개인적으로는 다양한 상황에서 프로그램을 구현할 때 파이썬을 사용하면 개발 생산성이 굉장히 높다고 생각합니다하지만 애플리케이션이 보장해야 하는 요구 조건들이 많아지면 생산성이 높던 상황이 달라질 수 있습니다 저희 팀은 비즈니스에 활용되는 애플리케이션을 파이썬으로 개발하는 경우 파이썬의 타입 어노테이션을 활용하고 있습니다 구체적으로는 mypy의 strict 옵션을 활성화해 모든 변수와 함수에 유의미한 타입 어노테이션을 기술하도록 강제하고 있습니다사용자 지표 애플리케이션을 개발할 때도 마찬가지로 타입 어노테이션을 강제했습니다 그 결과 파이썬으로 개발을 하고 있는데도 러스트에서처럼 여러 타입을 오가며 씨름하는 시간이 필요하게 되었습니다 이 때문인지 사용자 지표 애플리케이션을 두 가지 버전으로 구현하면서 파이썬과 러스트 간의 개발 시간 차이를 크게 체감하지는 못했습니다반면 생산성 측면에서 체감되는 가장 큰 차이점은 컴파일 시간이었습니다 러스트는 긴 컴파일 시간을 가지고 있는 언어이고 파이썬은 컴파일이 필요 없는 언어기 때문입니다 참고로 러스트로 작성된 사용자 지표 애플리케이션의 릴리즈 빌드 시간은 4 코어Skylake IBRS 환경에서 대략 280초입니다 패키지 다운로드와 빌드 시간을 포함한 도커 이미지 빌드 시간을 비교하면 러스트는 대략 340초 수준이고 파이썬의 경우 대략 100초 수준입니다이와 같은 러스트의 긴 컴파일 시간은 개발 주기를 민첩하게 가져가지 못하게 하며 개발자의 생산성을 조금씩 방해합니다 비록 러스트의 증분 빌드 기능이 뛰어나기 때문에 개발 중에 모든 소스를 컴파일할 일은 잘 없지만 코드 구현이 빌드 과정마다 조금씩 보류되면서 작업자의 집중력을 떨어뜨리기에 충분합니다 또한 테스트를 수행하고 배포를 하는 과정이 길기 때문에 전체 개발 주기를 조금씩 느리게 만듭니다 환경에 따라서 컴파일 시간이 달라지겠지만 컴파일이 필요 없는 파이썬과 비교하면 긴 컴파일 시간은 러스트의 큰 단점이라고 할 수 있습니다 개발 경험 이 주제에서는 개인적으로 느낀 개발 경험을 말씀드리고 그 과정에서 사용했던 도구의 차이를 간략하게 서술하겠습니다먼저 타입 시스템입니다 이전에도 언급했지만 저희 팀은 파이썬에서 타입 어노테이션을 사용하고 있습니다 결국 파이썬과 러스트 모두 어떤 방식으로든 타입 시스템을 사용하고 있는데요 두 언어가 타입을 사용하는 방식에는 확실한 차이가 있었습니다PEP 484에 따라 파이썬의 타입 검사는 외부 정적 검사 도구를 사용해 수행됩니다 저희 팀이 사용하는 mypy의 경우 기본적인 타입 추론을 제공할 뿐만 아니라 제네릭과 프로토콜 관련 타입 검사에 대해서도 잘 동작하였습니다하지만 파이썬 외부 라이브러리를 사용하는 경우에 타입 검사를 패키지에 제대로 구현하지 않은 경우가 많아 구현 과정에서 종종 불편한 경험을 했습니다 타입 정보가 없는 라이브러리에서 만들어진 데이터는 타입 검사가 무시되는 Any 타입을 가집니다 이 Any 타입 데이터에서 파생되는 데이터 또한 불투명한 타입을 가지게 되고 전체 프로젝트에서 타입 검사 정확도를 낮추는 원인이 됩니다반면 러스트는 강타입의 현대 언어답게 타입 시스템을 보조하는 기능이 많습니다 컴파일러의 강력한 타입 추론 기능은 프로그램 구현 과정에서 타입에 관련된 개발 시간을 상당히 줄여주었습니다 예를 들어 다음과 같이 제너릭 타입인 bar 변수는 선언 당시 비결정적이지만 뒤에 사용되는 코드에 따라 그 타입이 결정됩니다 참고로 해당 예제의 경우 주석을 해제하면 타입 불일치 오류가 발생합니다 그리고 러스트는 이종Heterogeneous 유니언Union 타입인 열거형Enum 타입 불변성과 참조에 따라 나뉘는 다양한 타입 및 그것을 지원하는 타입 변환Coercion 등이 전체 타입 시스템을 보조하고 있어 타입을 사용하기 매우 편리했습니다또한 두 언어의 오류 처리 방식도 많은 차이가 있습니다 파이썬의 경우는 예외를 발생시키는 방식으로 오류를 처리합니다 발생한 예외는 사용자가 직접 처리할 수도 있고 처리를 구현하지 않는 경우에는 파이썬이 예외를 출력하고 프로그램을 종료시킵니다 반면 러스트에는 예외가 없습니다 Result라는 enum 타입으로 오류를 표현하는데 발생할 수 있는 모든 오류에 대해 어떻게 처리할지 명시하지 않으면 컴파일이 실패합니다 따라서 발생할 수 있는 오류에 대해 대응할 전략과 코드가 항상 구현되어 있어야 합니다 간단하게 만들어서 사용하는 스크립트라면 이와 같은 특성은 전체 생산성을 떨어뜨릴 수 있지만 안전성을 추구하는 애플리케이션이라면 장점으로 작용할 것 같습니다마지막으로 개발 도구도 언급하면 좋을 것 같습니다 두 언어 모두 개발 과정에서 패키지 관리자Package manager 린터Linter 포매터Formatter 유닛 테스트Unit test 등등 유지보수를 용이하게 하기 위해 많은 도구를 사용하고 있습니다 사용자 지표 애플리케이션에서 각각의 경우에 사용했던 도구를 표를 통해 요약하면 다음과 같습니다 러스트의 경우 cargo가 기본적으로 제공하는 기능이 많았습니다 파이썬 또한 최근에는 개발 도구가 많이 고도화되었기 때문에 설치만 한다면 비교적 쉽게 사용할 수 있었습니다 마치며 사용자 지표 애플리케이션을 간단하게 구현해 보며 러스트 데모를 성공적으로 마쳤고 현재는 기능 고도화 단계에 있습니다 도입을 하면서 느꼈던 장점들이 있었기에 팀 내부의 다른 프로젝트에도 러스트 도입을 시도하고 있습니다그럼에도 파이썬과 러스트는 각 언어의 특징과 장단점이 두드러지기 때문에 러스트를 도입하는 게 항상 옳은 결정은 아닙니다 위에서 언급드린 내용 외에도 관련 커뮤니티 레거시 연동 여부 및 개발 환경 등 도입을 위해 고려해야 할 부분이 많습니다 러스트를 도입한다면 무엇을 기대하는지 먼저 정의하고 환경에 따라 고려해야 할 다양한 조건들을 비교해 도입을 진행하시는 것을 추천합니다이로써 러스트와 파이썬으로 동일한 애플리케이션을 작성하면서 느낀 점들을 정리해 보았습니다 러스트 도입을 고민하시는 분들에게 작게나마 도움이 되었으면 좋겠습니다감사합니다 Connect with Kakao Tech,https://tech.kakao.com/storage/2022/02/kakao-tech-logo-1-e1649831117387.png,https://tech.kakao.com/2023/03/02/python-and-rust/
수제 FinOps - Trusted Advisor,수제 FinOps NAT편 에서 이어집니다 Trusted Advisor란 AWS 모범 사례를 따르는 데 도움이 되는 권장 사항을 제공해주는 서비스인데 리소스를 정기적으로 스캔해서 최적화하고 보안 및 성능을 개선해서 비용을 절감시킬 수 있는 서비스 중 하나입니다 아래 링크처럼 AWS에서는 주기적으로 매번 비용 절감할 수 있는 방법을 소개하지만 사실 귀찮아서 지키지 않는 항목들에 대해서 Trusted Advisor가 알아서 스캔해서 콘솔에 정리해서 보여준다는 겁니다 무려 공짜로 말이죠 AWS 비용을 줄일 수 있는 10가지 기법 저는 Trusted Advisor에 아무것도 안뜨는데요 물론 무료라곤 했지만 모든 계정에 대해서 다 공짜로 해주는건 아니고 Support Plan에 따라서 적용되는 항목이 다릅니다 AWS Trusted Advisor 참조 확인 어차피 링크 안들어가보실 것 같으니 필요한 부분만 스크린샷으로 떠왔습니다 아래 이미지처럼 Basic Developer Plan은 일부 항목만 제공해주기 때문에 개인 계정에서는 별 내용이 안나오긴합니다 제 개인계정도 이렇게 뜨거든요 하지만 저희 회사 계정은 Enterprise Support Plan이기도 하고사용하는 리소스가 많기 때문에 요렇게 조치해볼만한 내용이 뜹니다 제공되는 항목 일단 Trusted Advisor는 크게 5가지의 항목으로 나눠집니다 이 중에서 FinOps랑 관련 없는 것도 같이 한번 쓱 보면 아래와 같습니다 항목 설명 예시 비용 최적화 EBS Lambda오류율 EC2 RDS 등등 성능 EBS Lambda EC2 EFS에 대한 최적화 과소 과대 사용하는 리소스 보안 지원 종료 버전 스냅샷 권한 보안그룹 등등 내결함성 Multi AZ이중화 DB 백업RDS ElastiCache S3 로깅 서비스 한도 계정 내 리소스가 서비스 한도에 도달하거나 도달할 가능성이 있는 경우 더 자세한 항목은 아래 링크에서 보실 수 있습니다 AWS Trusted Advisor 참조 확인 비용 최적화 톺아보기 글의 주제는 FinOps니깐 비용 최적화 항목만 톺아보면 일단 세부적인 검사 내용은 아래 링크를 보시면 좋을거 같네요 비용 최적화 이 중에서 가장 비용을 많이 절감할 수 있는 포인트는 바로 EC2 RDS ElastiCache OpenSearch Lambda EBS ELB 입니다 네 사실 모두 절감 포인트긴합니다 하지만 여기서 중요한건 유휴 자원과 프로비저닝 최적화에 대해서 제공을 해준다는 점입니다하나씩 정리해서 보자면 1 낮은 사용률의 리소스 검사 주로 많이 검출되는 종류 중 하나인 낮은 사용률입니다 검사되는 기준은 아래와 같습니다 서비스명 기준 EC2 14일 중 4일 이상 인스턴스의 일일 평균 CPU 사용률이 10 이하 네트워크 IO가 5MB 이하 RDS 7일단 연결되지 않음 Lambda CloudWatch를 참고해서 알아서 판단 알아서 적절한 메모리 크기를 제안해줌 Elastic IPEIP EC2나 NAT 등에 연결되지 않음 EBS 볼륨에 연결되지 않거나 7일간 하루에 1 IOPS 미만인 경우 ELB 활성정상 상태의 타겟 그룹 없음 7일간 요청이 하루에 100개 미만인 경우 여기서 RDS EC2의 대부분은 검출되는 이유가최대 트래픽을 버티기 위해서 최대 크기의 타입을 사용해서 그런 경우가 많은데 개인적인 경험상 1년에 12번 발생할까 말까인데 그 상황 조차도 12시간인 경우가 많았습니다 그렇다고 장애 포인트를 안고 가자는건 아니고 단순하게 auto scaling으로도 커버할 수 있는 상황도 눈에 보였는데 귀찮아서 방치하시는 경우도 종종 보긴했었습니다 물론 말은 이렇게 하면서 저희팀 계정도 크게 다르진 않습니다퇴근하면 서버 끄고 가세요 아래 이미지는 저희팀 계정의 낮은 사용률의 EC2 리스트입니다 2 프로비저닝 최적화 이게 참 애매한 경우가 많은데요 AWS가 알아서 이제까지 리소스 사용량을 보고 리소스 크기를 추천해주는 겁니다 일단 과소과대 프로비저닝에 대한 검사되는 서비스는 아래와 같습니다 서비스명 기준CloudWatch 지표 EBS IOPS 처리량 Lamdba 과도한 실행 시간 초과 높은 오류율 7일 중 호출의 10 이상이 timeout이거나 error 메모리 크기에 대한 과다 프로비저닝 Lambda의 경우엔 사례가 있어서 스크린샷을 하나 가져와봤습니다그냥 메모리를 기본값인 128MB 으로 쓰고 있었는데 너무 적게 할당했다고 하네요 다만 알아서 추천해주다보니 이게 문제가 EBS는 처음에 너무 적게 할당해버리면 나중에 mount하기 귀찮은데 비용도 사실 얼마 안되서 크게 잡는 경우가 많습니다 단순히 1TB 유지하는데 겨우 91 10만원 정도거든요 보통 SSD 수명은 510년을 잡지만고가용성을 위해서 RAID로 구성한다면 수명이 극단적으로 짧아지게 됩니다 특히 API서버처럼 로그 파일이 양산하는 서버라면 쓰기 작업이 많아서 더 짧아질텐데 disk 100가 되서 서버가 죽거나 데이터 유실해보신 경험을 가지신 분들은 월 10만원이 결코 비싸지 않다는걸 아실 겁니다 물론 그런걸 감안해도 비싸다라고 하긴합니다 물론 SK하이닉스 SDD가격으로 비교해보면 EBS 1TB 1달 비용이 1개 값이긴 합니다 이렇게 보니 또 EBS가 비싸긴 비싸네요 그리고 Lambda도 메모리를 줄일 수 없는 이유는 1번에서 나왔던 내용과 같죠구현된 기능의 예상되는 최대치의 메모리를 잡아둬야하거든요 예를 들어서 주로 엑셀로 내보내기 기능을 많이 넣죠근데 그 엑셀 데이터가 1GB가 넘는다면 EC2에서 처리하나 Lambda에서 처리하나 어쨋든 예상되는 데이터 사이즈만큼의 메모리는 확보되어야합니다 물론 100MB씩 나눠서 파일 여러개로 받게할수도 있지만요건이 그렇게 정리 안될때가 많죠 아무튼 프로비저닝 최적화 부분은 참 좋지만 적용하기에는 애매한 친구입니다 그래서 이 부분은 필수가 아닌 권장 사항으로 나옵니다 3 예약 인스턴트RI Savings Plan 마지막은 가장 예측이 안되면서 잘못하면 돈날리기 좋은 부분인 예약 인스턴스입니다 다만 통합 결제에 연결된 계정에서는 이 항목을 볼 수가 없어서 Enterprise Support Plan인 분들은 오히려 볼 일이 없긴한데 아무튼 Trusted Advisor에서 제공해주는 RI 최적화 서비스는 아래와 같습니다 EC2 ElastiCache OpenSearchElasticSearch RDS Redshift 모두 30일동안 온디맨드 사용량을 분석해서 최적화된 RI 값을 추천해줍니다만 사실 참고 자료로만 쓰기 좋긴합니다 왜냐면이미 Trusted Advisor에서 RI를 걱정하고 계신다면이미 어느정도 규모의 리소스를 사용하시고 이미 어느정도 규모의 회사이실텐데 1달에 1번씩 Trusted Advisor에 나오는 걸 그대로 믿고 13년치를 냉큼 살 순 없죠 RI는 당연히 기간과 할인율은 비례하기 때문에아래처럼 주로 많이 쓰는 m타입만 봐도 1년과 3년 간의 할인율 차이가 18나 납니다 만약에 할인율에 눈이 돌아가서 3년 짜리를 샀다가 내년에 서비스를 종료해야되거나 사용자가 줄어서 구매한 서버가 남는다면 매우 큰 손해가 발생합니다 그리고 매 달마다 사는것도 스트레스죠 흔히 대기업에서는 서버 1대 사려면 최소 3개월은 걸린다고 할 정도인데 완전 소유하는것도 아니고 임대하는걸로 선결제로 구매하겠다 게다가 1달 비용이 그냥 서버 1대 구매하는 비용인데정말 많은 설득이 필요합니다그래서 보통 많아야 1년에 12번 정도만 구매를 하죠 물론 회사에서 돈 많이 벌때 RI 3년짜리로 땡겨두면 남은 2년이 편해지긴 합니다특히 달러 환율 낮을때 미리 구매해두면 왠지 추가 할인받는 느낌도 나고 이번 코로나때처럼 경기가 많이 위험할때 남들과 다르게 방탕하게 서버를 쓸 수 있죠 암튼 뭐 그렇기 때문에 참고 자료 정도로 좋다는 거 였습니다 결론 Trusted Advisor 자체로 직접적인 비용 절감한 경우는 잘없지만잘안쓰거나 남용하는 리소스에 대해서 모니터링이 가능하다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=165196&boardType=techBlog&searchData=&page=&subIndex=
너 혹시 T(Tester)야? : 테스트 효율을 높이는 Charles 툴 활용기,itemname subname 이미지 출처 민보우 드로잉 httpsbrunchcokrnofearbow94 들어가며 저는 2020년부터 2022년까지 약 3년간 배달의민족 앱의 QA품질 보증 업무를 담당하였습니다 배달의민족 앱을 테스트하려면 수많은 테스트 데이터가 필요한데 테스트 데이터를 모두 수동으로 만들 순 없습니다 테스트 데이터를 효율적으로 쌓기 위해 Charles라는 프록시 툴 을 도입하였습니다 프록시 서버와 클라이언트 사이에 중계기로서 대리로 통신을 수행하는 것을 가리킴 출처 위키백과 Charles 툴은 시스템과 인터넷 간의 모든 HTTP 및 SSLHTTPS 트래픽을 보고 가로채고 분석할 수 있는 웹 디버깅 프록시 기능에 특화되어 있습니다 요청 응답을 확인하는 것만이 아니라 일반적으로는 재현할 수 없는 상황을 만들거나 요청 응답 값을 조작 할 수 있고 이를 모바일 기기의 GUI로 확인 할 수 있어서 클라이언트 테스트 및 디버깅에 유용합니다 Charles의 강점 HTTP 요청응답을 가로채고 다른 값을 응답 Status code를 Error code로 응답 대기 시간을 포함하여 느린 인터넷 연결을 시뮬레이션하는 대역폭 조절 이 글에서는 Charles 툴을 테스트 활동에 사용하여 테스트 시간 감소에 도움을 받았고 효율적으로 테스트 데이터를 쌓는 등 적재적소에 툴을 활용했던 경험을 소개하고자 합니다 Charles 툴에 대해 1 Charles 사용 배경 QA에서 앱 테스트를 수행할 땐 아래 내용을 고려하여 서버와 클라이언트의 로직에 대한 테스트가 이루어집니다 클라이언트가 서버에 요청을 잘 보내고 있는지 서버에선 클라이언트의 요청을 처리하여 응답해 주는지 서버 응답대로 클라이언트가 화면을 그려주는지 위의 내용을 배달의민족의 가게로 풀어서 설명해 보면 아래와 같습니다 사용자가 배달의민족 가게 목록에서 A 가게를 클릭하면 클라이언트에서 서버에 A 가게의 데이터를 보여줘라고 요청합니다 서버에선 A 가게의 메뉴 리뷰 찜 카운트 등의 가게를 구성하고 있는 데이터를 정확하게 응답해 줍니다 클라이언트에선 서버 응답 기반으로 GUI를 제공해서 사용자와 인터페이스를 할 수 있게 해줍니다 이중 테스트에 가장 시간이 많이 필요한 건 어떤 항목일까요 테스트 데이터를 준비해야 하는 2번 항목 입니다 가게 테스트에 필요한 테스트 데이터를 몇 가지만 예를 들어보면 메뉴 데이터 리뷰 수 사장님 댓글 리뷰 별점 찜 카운트 배달팁 설정 등이 있겠네요 이처럼 가게를 구성하고 있는 경우의 수는 다양하고 이를 만족하기 위해선 많은 테스트 데이터가 필요 합니다 그림 1 배달의민족 가게 화면 만약 리뷰 수가 1000개가 넘어갈 때 세 자리마다 콤마가 찍히는지 봐야 하는 테스트가 필요한 상태라 가정해 보겠습니다 리뷰를 무조건 작성할 수 있는 테스트 계정이 있다고 가정하고 리뷰 1개 작성할 때 1분이 걸린다고 접근해 봐도 1000분이 걸리는 많은 시간이 소모되는 작업입니다 물론 QA 조직에서 이렇게 수동으로 데이터를 만들진 않습니다 예시라 봐주세요 어떻게 하면 효율적으로 테스트 데이터 를 만들 수 있을까요 예전에 스타크래프트라는 게임이 있었고 이 게임엔 치트키라는 게 있었습니다 웬 치트키 얘기냐고요 가게 응답 값에서 리뷰 수를 제공해 주는 파라미터를 치트키처럼 원하는 대로 값을 바꿀 수 있다면 어떨까요 실제론 서버에서 가게에 등록된 리뷰 수를 계산해서 응답을 전달하지만 이를 가로채서 원하는 값으로 바꾼 후 클라이언트에서 GUI를 잘 제공해 주는지만 테스트한다면 단순 비율로만 계산했을 때 서버 클라이언트 모두 테스트하는 것 대비 절반의 시간 으로 테스트를 진행할 수 있을 것입니다 이런 치트키 같은 도구가 Charles와 같은 프록시 툴입니다 2 Charles의 특징 프록시 기능과 모바일 기기 GUI 연동 API 테스트를 진행할 때 많이 사용하는 툴은 Postman PAW 등이 있습니다 이들 툴이 API 요청 응답에 대한 테스트에 특화되었다면 Charles는 시스템과 인터넷 간의 모든 HTTP 및 SSLHTTPS 트래픽을 보고 가로채고 분석할 수 있는 웹 디버깅 프록시 기능에 특화되어 있는 차이가 있습니다 Charles 툴 활용사례 그러면 Charles의 특징과 툴을 어떻게 활용하여 테스트를 했는지 공유해 보겠습니다 1 서버 응답 데이터 변조 배달의민족의 가게는 사용자가 찜을 할 수 있고 찜한 가게들만 별도로 확인할 수 있습니다 찜의 카운트는 9999까지는 서버의 데이터를 그대로 표시하지만 10000 카운트가 넘어가게 되면 1만 라고 클라이언트에서 가공 처리를 해주어야 합니다 1만 라고 클라이언트에서 표시해 주는지 확인을 위해선 1대의 디바이스 혹은 1개의 배민회원으론 가게에 찜 등록을 한 번만 할 수 있기 때문에 찜이 1만 개인 가게 테스트 데이터를 만들기 위해선 1만 대 디바이스 혹은 1만 개의 배민 회원 계정 이 필요합니다 수동으로 설정하긴 불가능한 테스트 데이터라 SQL을 활용하여 db를 조작하여 데이터를 만들 수밖에 없습니다 db 접근 권한이 없거나 SQL 관련 지식이 없으면 서버 개발자에게 데이터 설정을 요청해야 하는데 이로 인한 커뮤니케이션 리소스가 소모됩니다 Charles의 프록시 기능을 활용하여 서버 응답 값을 변조하여 로컬 환경에서 재현시키는 방법으로 간단하게 테스트를 할 수 있습니다 그림 2 Charles로 서버 응답 데이터 가로채고 대체하는 과정 배달의민족 가게 상세 API에서 서버 응답받은 찜 카운트 값을 변조하는 방법을 적어보겠습니다 Charles로 API의 서버 응답 값 변조 방법 배달의민족 가게 상세 API 명세서에서 찜의 데이터를 노출시켜주는 파라미터와 응답 구조 확인 파라미터와 응답 구조는 보안 문제 발생 감안하여 업로드하진 않겠습니다 JSON Editor tool을 사용해 실제 서버 응답을 가로채고 대체할 API 응답 값을 JSON 구조로 만들기 JSON Editor tool은 Visual Studio Code 추천합니다 파싱 에러 발생 시 툴에 표시해 주기도 하고 무엇보다 무료라는 강점이 있습니다 Visual Studio Code 다운로드 Charles 실행 Sequence 목록에서 배달의민족 가게 상세 API 마우스 오른쪽 클릭 Map Local 선택 Edit Mapping 창의 Local path에서 대체할 JSON 파일 업로드 Charles와 연결된 모바일 기기로 배달의민족 가게 상세 화면 진입 시 대체한 응답 파일구조로 클라이언트에서 화면에 그려주는 것을 확인 가능 그림 3 가게의 찜 카운트 응답 값 전후 변화 사진 2 서버 API 에러 응답 상황에서 클라이언트 동작 확인 사용자들이 앱을 사용하며 API가 호출될 때 항상 정상적인 200 코드 응답만 받으며 잘 동작되는 것은 아닙니다 클라이언트의 요청에서 문제가 있는 경우 응답받는 400번대 코드 서버 API에 문제가 있는 경우 응답받는 500번대 코드 위와 같이 에러 응답을 받는 상황이 있고 에러 응답을 받으면 클라이언트는 서버의 응답 데이터로 화면을 정상적으로 그려줄 수 없습니다 사용자를 고려한 서비스라면 이런 예외적인 상황에서 사용자에게 에러 상태인 걸 가시화해서 보여주고 재시도 화면 이탈 등의 액션 이벤트를 시도할 수 있게 해주는 유저 플로우가 필요합니다 그림 4 배달의민족 배달 현황 화면의 API가 에러 응답을 받는 상황 이에 대한 테스트의 결과를 도출하기 위해선 아래와 같은 번거로운 절차가 필요합니다 서버 개발자에게 테스트 서버에 장애를 만들어달라고 요청 에러 응답 상황 만들기 테스트 수행 테스트 완료 시 원복 요청 코드 수정 후 원복 이것만으로도 커뮤니케이션 리소스가 발생되는데 더욱 큰 문제는 테스트 서버를 사용하는 모든 유관부서 인원에게 영향을 미칠 수 있단 점 입니다 10분 동안 100명이 테스트 서버를 사용 못 한다고 했을 때 낭비되는 시간은 1000 분이 될 것입니다 이렇게 에러 응답을 받는 상태에 대한 테스트도 charles의 프록시 기능을 활용하여 QA 인원 개인의 로컬 환경에서 테스트 서버에 전혀 영향을 주지 않고 테스트 가능합니다 배달의민족 가게 목록 API에서 500 응답을 받는 상황을 로컬에서 만들어서 테스트하는 방법을 공유해 보겠습니다 Charles로 API 200 응답 500 응답으로 변경하는 방법 Charles 실행 Sequence 목록에서 사용하고자 하는 API를 선택 마우스 오른쪽 클릭 Copy URL 선택 Tools Rewrite 메뉴 진입 Enable Rewrite 체크 Add 버튼 선택하여 Rewrite 항목 추가 Name 입력 후 Location의 Add 버튼 선택하여 Edit Location 창 불러온 후 아래 값 입력 Protocol http https 중 선택 Host 가게 목록 API 입력 복사 붙여넣기 가능 Path API Path 입력 Host에 URL 붙여넣기 후 키보드의 Tab 키 선택 시 자동으로 값 채워짐 Query 특정한 정보를 요청하여 Rewrite 대상을 한정할 경우 입력 Host에 URL 붙여넣기 후 키보드의 Tab 키 선택 시 자동으로 값 채워짐 Type의 Add 버튼 선택하여 Rewrite Rule 창 불러온 후 아래 값 입력 후 저장 Type Response Status Match Value 200 Replace Value 500 모바일 기기로 Rewrite Rule을 설정한 API인 가게 목록 화면을 진입하여 API 요청 응답이 이루어지면 절차 6에서 대체한 500 Status 에러 응답을 받기 때문에 클라이언트 화면에서 에러 화면을 제공해 주는지 다시 시도 액션 이벤트가 잘 이루어지는지 등의 테스트를 서버 장애 상황이 아닌 경우에도 가능 그림 5 가게 목록 API가 200 응답일 때와 500 응답일 때 앱 화면 비교 그림 6 가게 목록 API가 200 응답일 때와 500 응답일 때 Charles 화면 비교 3 Timeout 상황 테스트 Timeout은 프로그램이 특정한 시간 내에 성공적으로 수행되지 않아서 진행이 자동적으로 중단되는 것을 말합니다 만약 앱에 Timeout이 구현되지 않았다면 엘리베이터나 만원 지하철 등 네트워크가 느려질 수 있는 상황에서 API 호출하였을 때 끝없이 로딩이 발생 될 수 있습니다 Timeout이 구현되었다면 일정 시간 이후 API 호출 시도가 자동적으로 중단됩니다 Timeout 테스트는 일반적인 도심의 사무실 환경에선 테스트하기가 쉽지 않지만 Charles는 앱의 Timeout 상황을 재현하여 테스트할 수도 있습니다 배달의민족의 가게목록에서 가게를 선택하는 시점에 timeout이 발생하는 테스트 상황을 만드는 내용을 영상과 함께 공유하겠습니다 영상 1 latency ms를 10000ms로 설정하고 배달의민족 앱에서 Timeout 상황 재현 Charles로 Timeout 상황 재현 방법 Charles 실행 Proxy Throttle settings 선택 Enable Throttling 체크 특정 Host에만 throttle 설정을 하고 싶으면 Only for selected hosts 체크하고 Host 정보를 입력 체크를 하지 않으면 모든 요청에 throttle 설정이 적용 상세 설정값들을 테스트에 적절한 값으로 입력 후 적용 throttle preset 3G 4G 등 일반적인 인터넷 연결 유형을 설정 Bandwidth 전송할 수 있는 최대 데이터양을 정의합니다 Utilisation 한 번에 사용자가 접근할 수 있는 전체 대역폭의 백분율 Roundtrip latency 클라이언트와 원격 서버 간의 요청 지연 시간 ms MTU 현재 프리셋의 최대 전송 단위를 정의 stability 연결이 완전히 실패할 가능성을 측정 신뢰할 수 없는 네트워크 조건을 시뮬레이션 하는 데 사용 Unstability quality range 연결이 불안정한상태 일 가능성을 측정하여 품질을 저하 시킴 주기적으로 연결 품질이 떨어지는 모바일 네트워크와 같은 네트워크를 시뮬레이션 할 때 사용 앱에서 API 호출이 발생되면 throttle 설정이 적용되어 네트워크 지연 상태일 때의 클라이언트 동작을 확인할 수 있습니다 Charles 꿀팁 Charles를 사용하며 막히는 부분을 해결했던 다양한 꿀팁들을 공유합니다 Charles 실행 시 노트북Mac에서 인터넷이 되지 않는 문제 Proxy macOS proxy 체크 해제 시 정상적으로 인터넷 사용 가능합니다 인증서 만료 상태 Help SSL Proxying Reset Charles Root Certificate 선택 팝업에서 Reset 선택 인증서 재 다운로드하면 신규 인증서 다운로드 가능합니다 Android 기기에서 CA 인증서를 설치할 수 없음이라는 에러 팝업 노출되며 인증서 설치 불가능한 경우 휴대폰 설정 생체 인식 및 보안 기타 보안 설정 디바이스에 저장된 인증서 설치 CA 인증서 메뉴 진입하여 해당 인증서를 설치하면 됩니다 OS ver 70 이상의 Android 기기에서 앱과 Charles의 연결이 되지 않는 경우 Charles SSL Proxying에서 생성된 SSL 인증서를 신뢰하도록 앱에 네트워크 보안 구성 파일을 추가해야 합니다 이 파일은 시스템 기본값을 재정의하여 앱이 사용자가 설치한 CA 인증서예 Charles Root Certificate를 신뢰하도록 할 수 있습니다 아래 URL과 함께 협업하는 Android 개발자에게 공유해 주세요 httpswwwcharlesproxycomdocumentationusingcharlessslcertificates httpsdeveloperandroidcomtrainingarticlessecurityconfighlko httpsstackoverflowcomquestions39215229howtogetcharlesproxyworkwithandroid7nougat 응답 값이 제대로 나오지 않는 문제 SSL Proxying settings에 포함되지 않은 Location들을 확인한 경우입니다 Proxy SSL Proxying settings 메뉴 진입 후 요청과 응답 값에 대한 정보를 확인하기 위한 세팅이 필요합니다 Include 영역의 Add 버튼 클릭하여 Location을 입력합니다 예시 아래 이미지처럼 설정 후 charles에서 baemin이나 smartbaedal이란 키워드가 포함된 API들이 레코딩 될 경우 응답 값이 깨지지 않습니다 그림 7 SSL Proxying settings 전하고 싶은 이야기 Charles로 클라이언트 테스트하는 방법을 몇 가지 케이스와 함께 설명해 보았는데 간단히 정리해 보겠습니다 서버 응답 값을 대체하여 로컬 환경에서 클라이언트 테스트가 가능하므로 클라이언트 테스트만 할 경우 테스트 속도를 50 이상 단축 할 수 있습니다 어드민으로 만들어야 할 테스트 데이터들을 응답 값 변경으로 대체 가능합니다 서버에서 데이터를 응답해 주지 못하는 상황에서도 테스트 가능합니다 텍스트 길이 가게 응답 수 유효하지 않은 데이터 등으로 응답 값을 대체하여 서버에서 제한하는 스펙의 한계를 넘어서 테스트할 수 있습니다 API 에러 응답 상황 Timeout 등 일반적으로 테스트할 수 없는 상황 에 대한 유저 플로우 테스트가 가능합니다 요청 응답 값 등을 모바일 기기의 GUI와 함께 확인 가능하여 화면만 보고 테스트를 하는 것보다 더욱 정밀한 테스팅 을 할 수 있습니다 클라이언트와 서버 개발팀이 분리된 기능 중심 조직이라면 각 팀의 산출물에 대한 테스트 일정을 별도로 진행 하여 한결 유연한 관점으로 테스트 일정 접근이 가능합니다 배달의민족 푸드서비스 조직에선 클라이언트와 서버의 QA 인원이 별도로 있기에 QA 인력을 클라이언트와 서버에 분산 배치하여 각 조직의 개발 산출물을 별도의 일정으로 테스트를 진행하였습니다 이에 대한 배경은 같은 팀 임선진님이 쓴 가파르게 성장하는 서비스를 담당한 한 품질담당자의 회고 를 먼저 읽어보시면 이해가 빠를 것 같습니다 서버와 클라이언트의 QA RR이 분리되어 있었고 서버 로직에 대한 검증을 별도로 진행하는 동료 들이 있었습니다 따라서 클라이언트에 집중하여 테스트 전략을 수립할 필요가 있었고 Charels를 활용하여 앱 배포 주기 내에 많은 과제에 대한 QA 업무를 진행할 수 있었습니다 다만 모든 테스트를 Charles를 통해 서버 응답을 대체하여 테스트를 하는 건 위험 할 수 있습니다 로컬에서 잘 동작돼도 서버에서 데이터를 잘 처리해서 제공해 주지 못한다면 사용자에게는 전혀 의미가 없는 결과이기 때문입니다 어디까지나 Charles는 테스팅의 보조 수단으로 활용이 되어야 하며 서버 코드 수정 없이 클라이언트만 코드 수정이 있는 상황에서 Charles를 활용한다면 더욱 빠르고 효율적인 테스팅을 할 수 있을 것입니다 참고 Charles documentation 부록 Charles 설치 방법 Charles 공식 홈 에서 OS에 맞는 설치 파일을 다운로드 하여 설치합니다 라이선스를 구매하지 않는다면 30일간 free trial 버전을 사용할 수 있고 라이선스 비용은 사용할 인원에 따라 다른데 최저 50 최대 700달러의 비용이 필요합니다 Charles 실행 Proxy Proxy settings 메뉴 진입하여 Proxies 탭의 Port 8888 입력합니다 그림 8 포트 입력 Proxy Recording settings 메뉴 진입 후 Include Exclude 탭에 정보를 등록합니다 Include Recording 대상에 포함되는 정보 Exclude Recording 대상에 포함되지 않는 정보 그림 9 Recording settings 모바일 기기의 와이파이 설정 화면에서 각 항목에 아래와 같이 값을 입력합니다 OS ver에 따라 항목 명칭은 조금씩 상이할 수 있습니다 프록시 수동 프록시 호스트 이름서버 Charles가 설치된 PC의 IP 주소와 동일한 IP 주소 입력 프록시 포트포트 8888 입력 그림 10 모바일 기기 와이파이 설정 화면 모바일 기기의 웹 브라우저 주소창에 charlesproxycomgetssl 입력하여 링크 이동 시 자동으로 인증서가 다운로드 되며 OS에 맞는 방법으로 인증서를 설치합니다 Android 파일 관리자 앱으로 다운로드한 인증서 설치 iOS 설정 일반 정보 인증서 신뢰 설정 설치한 Charles 인증서 토글 ON 설정 일반 프로파일 및 기기 관리 Charles Proxy 프로파일 설치 인증서 설치까지 완료된 후 모바일 기기로 API 호출 동작이 일어나는 이벤트 발생 시 레코딩되어 Charles로 요청 응답 값 확인이 가능합니다 그림 11 Charles로 레코딩되는 API의 요청 응답값을 확인 가능,https://i.ibb.co/NtYzdMY/2024-01-04-174021.png,https://techblog.woowahan.com/14550/
기능 테스트 전환 이야기,안녕하세요 키친보드 제품팀의 백엔드 프로그래머 남경호입니다 2월에 작성한 청구수납 서비스 개발기 를 이후로 오랜만에 글을 작성하게 되었네요 이번 글은 지난번과 같은 서비스에 대한 내용이 아닌 좀 더 기술적인 내용을 다루어 보려고 합니다 혹시 2022년에 작성했던 서버 언어 전환 이야기 글을 기억하실까요 저희 백엔드 챕터에서는 언어 전환을 하면서 테스트 코드 작성에 대한 숙련도 문제 데이터 초기화의 불편함 등과 같은 여러 이유로 인해 통합테스트를 선택하게 되었었고 이로 인해 아래와 같은 이슈들을 겪게 되었습니다 그동안 저희 백엔드 챕터는 서비스를 발전 시켜가면서 수많은 테스트 코드를 작성하였고 자연스레 테스트 코드 작성에 대한 숙련도를 높일 수 있게 되었고 기능테스트 작성에 대한 난이도를 어느 정도 감수할 수 있다고 판단했습니다 그래서 통합테스트에 대한 단점을 보완하고 좀 더 변경에 대한 안정감을 느끼며 서비스를 개발하기 위해 그동안 묵혀두었던 기능 테스트로의 전환을 아래와 같이 2023년 목표로 설정하고 제품을 개발할 때 틈나는 대로 전환 작업을 진행해 왔습니다 모두가 노력해 준 덕분에 올해 목표로 했던 기능 테스트로의 전환을 마무리할 수 있게 되었는데요 그동안 저희가 통합 테스트에서 기능테스트로 왜 전환하게 되었는지 전환하면서 어떤 이슈들을 겪었는지 소개해 드리고자 합니다 기능 테스트 테스트 방법을 이야기할 때 단위 테스트 나 통합 테스트 는 수많은 서적이나 블로그 글에서 다루어질 만큼 개발자에게 익숙한 테스트 방법일 것으로 생각합니다 하지만 기능 테스트는 여러 매체에서 언급되지 않을 정도로 익숙한 용어는 아닌 것 같습니다 그래서 먼저 이 글에서 전반적으로 이야기할 기능 테스트라는 단어를 먼저 정의하고 시작해 볼까 합니다 테스트는 여러 가지 의미로 해석됩니다 E2EEnd to End 테스트 로 보기도 하고 통합 테스트 혹은 시스템 테스트 와 유사한 테스팅 기법으로 해석되기도 합니다 위키피디아의 기능 테스트 를 보면 아래와 같이 정의되어 있습니다 In software development functional testing is a quality assurance QA process and a type of blackbox testing that bases its test cases on the specifications of the software component under test 소프트웨어 개발에서 기능 테스트는 품질 보증QA 프로세스이며 테스트 대상 소프트웨어 구성요소의 사양을 바탕으로 테스트 사례를 작성하는 일종의 블랙박스 테스트를 말한다 특히 아래 구문에서 기능 테스트가 E2E 테스트와 구분이 된다고 생각하는데요 Functional testing does not imply that you are testing a function method of your module or class Functional testing tests a slice of functionality of the whole system 기능 테스트는 모듈 또는 클래스의 기능방법을 테스트한다는 의미가 아니다 기능 테스트는 전체 시스템의 일부 기능을 테스트한다 E2E 테스트는 End to End 즉 종단 간 테스트를 의미합니다 보통 실제 사용자 관점에서 테스트를 수행하기 때문에 브라우저 환경에서 테스트하는 Selenium appium 과 같은 도구를 통해 테스트를 수행합니다 하지만 저희는 서버의 API 범위에 한정해서 테스트하므로 E2E 테스트라고 보기 어렵다고 생각했습니다 한편 누군가는 통합 테스트와 같은 의미이지 않은가 하고 이야기할 수 있을 것 같습니다 통합 테스트가 단위 테스트를 거친 여러 모듈을 그룹화하여 테스트를 적용한다는 점과 단위 테스트와 시스템 테스트혹은 E2E 테스트의 사이에 진행한다는 점에서 같은 의미로 해석될 수 있다고 생각합니다 사실 통합 테스트를 좀 더 나은 테스트 방식으로 변경했다고 봐도 될 것 같긴 합니다 다만 동일한 통합 테스트라고 명명하기보다 좀 더 명시적으로 구분할 수 있는 테스트 방법을 표현할 수 있는 명칭이 필요하다고 생각했습니다 그리고 일부 모듈들의 집합을 테스트할 수 있는 통합 테스트에 비해 API의 끝점Endpoint에서 블랙박스로 테스트한다는 부분이 좀 더 강조되는 기능 테스트가 저희가 전환하는 목적성에 잘 부합한다고 생각해서 기능 테스트라고 부르기로 하였습니다 왜 기능 테스트로 전환하기로 하였나요 서버의 언어 전환을 진행한 이후로 백엔드 챕터에서는 모든 제품의 기능을 개발할 때 단위 테스트와 통합테스트를 작성하도록 하였습니다 코드 리뷰를 할 때도 동료가 작성한 코드의 스타일 뿐만 아니라 누락된 테스트 케이스가 없는지 체크해 줌으로써 기능적인 결함이 없도록 모두가 노력하였고 그 덕인지 QA에서 발생하는 서버의 버그 비율은 10 내외로 유지할 수 있게 되었습니다 저희는 여기에 만족하지 않고 좀 더 버그 비율을 줄일 방법이 있을지 찾아보았습니다 백엔드 전체 버그 이슈의 절반은 관리자와 관련된 이슈이고 그 나머지 중 13은 불명확한 요구사항으로 인해서 나머지 13은 코드 오류 또는 테스트 케이스 누락 나머지 13은 통합테스트에서 발견하지 못한 버그로 인해 발생한 것이었습니다 불명확한 요구사항이나 개발자의 실수로 인한 버그는 백엔드 챕터 외적인 요소이거나 장기적으로 개발자의 실수를 줄일 방안을 찾아나가야 한다고 판단해서 제외하고 마지막 13인 통합테스트에서 발견되지 않은 버그로 인한 이슈에 집중하기로 하였는데요 먼저 통합테스트로 인해 발견하지 못한 대표적인 사례들을 소개해 보면서 왜 통합 테스트에서 버그를 발견하지 못하게 되었는지 소개해 보겠습니다 사례 Hibernate Lazy Loading 먼저 Hibernate의 Lazy Loading으로 인해 발생한 버그인데요 구현된 버그가 발생한 코드를 먼저 보고 이야기를 이어가 보겠습니다 Entity class OrderableVendorProduct 생략 OneToMany mappedBy product fetch FetchType LAZY cascade CascadeType ALL orphanRemoval true protected val singleProductBundle MutableSet OrderableVendorProductBundle mutableSetOf val productBundle get singleProductBundle firstOrNull fun update data OrderableVendorProductUpdateData name data name unit data unit standard data standard erpCode data erpCode unitPrice data unitPrice isMarketPrice data isMarketPrice fun syncBundle if productBundle null throw IllegalStateException 묶음품목이 없는 품목은 묶음을 동기화할 수 없습니다 val bundleProduct productBundle bundleProduct bundleProduct name this name bundleProduct standard makeBundleStandard this standard productBundle unitCount this unit bundleProduct erpCode this erpCode Entity class OrderableVendorProductBundle product OrderableVendorProduct 생략 ManyToOne optional false JoinColumn name id nullable false insertable false updatable false val product OrderableVendorProduct product Service class OrderableVendorProductService 생략 Transactional fun update orderableVendorProductId UUID data OrderableVendorProductUpdateData OrderableVendorProduct 1 품목 조회 val product getOrderableVendorProductById orderableVendorProductId 생략 2 품목 데이터 업데이트 product update data 3 묶음 품목 조회 product productBundle let 4 묶음 품목이 존재하면 동기화 product syncBundle return product Entity로는 품목 과 묶음 품목 이 존재하고 양방향 연관관계를 가지고 있는 것을 볼 수 있습니다 그리고 OrderableVendorProductServiceupdate 함수를 보시면 ID를 이용하여 품목을 조회 하고 품목 데이터를 업데이트 하는데 묶음 품목이 존재 하면 묶음 품목을 동기화 해 주는 것을 볼 수 있습니다 만약 품목 에 묶음 품목 이 존재하면 update 함수가 기대했던 대로 동작할까요 예상하셨겠지만 아쉽게도 기대했던 대로 동작하지 않고 품목 은 수정하기 전 상태 그대로 존재하게 됩니다 왜일까요 이유는 Hibernate의 Lazy Loding과 영속 메커니즘 때문입니다 update 함수가 수행되는 순서대로 차근차근 살펴보겠습니다 품목 ID를 이용해서 품목을 조회합니다 조회한 품목을 수정합니다 조회한 품목의 묶음 품목을 조회합니다 묶음 품목 의 FetchType 이 Lazy 이기 때문에 호출 시점에 묶음 품목을 조회합니다 이때 묶음 품목의 연관관계인 품목 도 함께 조회됩니다 품목 정보를 동기화합니다 syncBundle 함수를 보시면 묶음 품목의 품목 정보를 조회하여 묶음 품목정보의 데이터를 업데이트해 준다는 것을 볼 수 있습니다 문제는 3번에서 발생합니다 묶음 품목 에서 조회한 품목 정보의 ID는 1번에서 조회한 품목 의 ID와 동일합니다 양방향 연관관계를 가졌으니까요 그러다 보니 Hibernate의 영속 메커니즘에 따라 캐시 된 Entity 정보를 조회하게 되고 2번에서 수정한 품목 정보는 3번에서 조회한 품목 정보에 의해 덮어씌워지게 되면서 수정한 데이터가 반영되지 않게 되는 것입니다 눈으로 직접 확인해 보기 위해 로그를 출력해 보았습니다 println 11111111 println productorderableVendorCatalogProduct product update data println 22222222 println productorderableVendorCatalogProduct product productBundle let println 33333333 println productorderableVendorCatalogProduct product syncBundle println 44444444 println productorderableVendorCatalogProduct 11111111 comspoqacartdomainorderableVendorOrderableVendorCatalogProduct9671a783 22222222 null Hibernate select s10ids10bundleproductids10createdats10unitcount from orderablevendorproductbundle s10 where s10id Hibernate select o10ido10createdato10erpcodeo10ismarketpriceo10nameo10orderablevendorido10orderablevendorcatalogproductido10standardo10unito10unitpriceo10updatedato10vatincluded from orderablevendorproduct o10 where o10id in 33333333 comspoqacartdomainorderableVendorOrderableVendorCatalogProduct9671a783 44444444 comspoqacartdomainorderableVendorOrderableVendorCatalogProduct9671a783 2번 로그를 보시면 분명 orderableVendorCatalogProduct 를 null 로 업데이트하였음에도 불구하고 3번 로그에서 다시 조회됨을 볼 수 있습니다 Hibernate Flushing Hibernate와 관련해서 좀 더 단순한 다른 이슈를 더 보겠습니다 이번에는 Hibernate의 Flushing 메커니즘과 관련한 이슈입니다 Entity class Reconciliation transactionDate LocalDate Column nullable false unique true val transactionDate LocalDate transactionDate 생략 Service class ReconciliationWriter 생략 Transactional fun write results List PaymentTransactionComparisonResult Reconciliation val transactionDate getTransactionDate results first 1 거래일 기준 대사 삭제 reconciliationRepository deleteByTransactionDate transactionDate val reconciliation createReconciliation transactionDate results 2 대사 저장 return reconciliationRepository save reconciliation 위 코드를 보시면 코드상으로는 문제가 없어 보입니다 거래일 기준으로 대사 정보를 삭제하고 해당 거래일 기준으로 대사를 다시 생성한 후 저장합니다 기존 데이터를 삭제하고 새로운 데이터를 생성하기 때문에 거래일이 유일 제약조건이 걸려있어도 문제없어 보입니다 통합테스트에서도 정상적으로 동작합니다 하지만 실제로 서버를 실행해서 기능을 수행해 보면 아래와 같이 오류가 발생합니다 58144180 scheduling1 ERROR ERROR duplicate key value violates unique constraint reconciliationtransactiondateuk Detail Key transactiondate20230201 already exists 데이터를 삭제하고 저장했는데 왜 유일키 제약조건 위반 오류가 발생할까요 이유는 Hibernate의 Flushing 메커니즘 때문입니다 Hibernate의 AbstractFlushingEventListenerperformExecutions 의 동작 방식을 보면 아래와 같이 적혀있습니다 Execute all SQL and secondlevel cache updates in a special order so that foreignkey constraints cannot be violated Inserts in the order they were performed Updates Deletion of collection elements Insertion of collection elements Deletes in the order they were performed 그래서 위에 적힌 ReconciliationWriterwrite 함수는 2 대사 저장 후 1 거래일 기준 대사 삭제 를 수행하는 순서로 실행되게 됩니다 그래서 저장을 먼저 수행하고 데이터를 삭제하니 유일키 제약조건을 위반하는 것입니다 Transactional Event Listener 이번에는 Hibernate가 아닌 SpringFramework에서 제공하는 TransactionalEventListener 로 인해 발생했던 이슈를 살펴보겠습니다 아래 코드는 유통사 계정을 생성하는 Facade의 구현 코드입니다 Service class OrderableVendorAccountFacade 생략 Transactional fun createAccount data CreateOrderableVendorAccountFacadeData OrderableVendorAccount 생략 1 유통사 계정을 생성합니다 val createdAccount orderableVendorAccountService createAccount createOrderableVendorAccountData 2 샌드버드 사용자를 생성합니다 val response chatClient createOrderableVendorAccountChatUser createdAccount 3 샌드버드 사용자 ID를 생성한 유통사 계정에 업데이트 합니다 orderableVendorAccountService updateSendbirdUserId orderableVendorAccountId createdAccount id newSendbirdId response userId toString return createdAccount Service class OrderableVendorAccountService 생략 Transactional fun createAccount data CreateOrderableVendorAccountData OrderableVendorAccount 생략 11 유통사 계정을 생성합니다 return orderableVendorAccountRepository save account also 12 유통사 계정 생성 이벤트를 발행합니다 eventPublisher publishEvent OrderableVendorAccountCreatedEvent account id Component class ChatEventHandler 생략 TransactionalEventListener fun handle event OrderableVendorAccountCreatedEvent 생략 121 유통사 계정 생성 이벤트를 받아 유통사의 모든 채팅방에 계정을 초대합니다 chatClient inviteOrderableVendorAllChannels account Component class ChatClient 생략 fun inviteOrderableVendorAllChannels account OrderableVendorAccount account orderableVendor orderChannels forEach 1211 모든 주문채널에 계정을 초대합니다 queueMessageSender inviteSendbirdChannelUser SendbirdInviteChannelUserQueuePayload channelUrl it payload SendbirdGroupChannelInvitePayload userIds listOf account sendbirdId queueMessageSender inviteSendbirdChannelUser 1212 문의 채널에 계정을 초대합니다 SendbirdInviteChannelUserQueuePayload channelUrl INQUIRYaccountorderableVendorid payload SendbirdGroupChannelInvitePayload userIds listOf account sendbirdId 클래스가 분리되어 있다 보니 코드의 실행 순서를 따라가기 힘드실 거라 생각되어 위에 적힌 계정 생성 기능의 코드 순서를 아래와 같이 정리해 보았습니다 유통사 계정을 생성합니다 1 유통사 계정을 생성합니다 11 유통사 계정 생성 이벤트를 발행합니다 12 유통사 계정 생성 이벤트를 받아 유통사의 모든 채팅방에 계정을 초대합니다 121 모든 주문 채널에 계정을 초대합니다 1211 문의 채널에 계정을 초대합니다 1212 샌드버드 사용자를 생성합니다 2 샌드버드 사용자 ID를 생성한 유통사 계정에 업데이트합니다 3 한날 어느 개발자가 유통사 계정을 생성하는 코드를 리펙터링하는 도중 ChatEventHandlerhandle 함수에 기재된 TransactionalEventListener 를 모종의 이유로 EventListener 로 변경하게 되었습니다 코드를 변경하고 나니 56번 항목인 채팅방에 계정을 초대하는 부분에서 오류가 발생하였는데요 이유를 살펴보니 아래와 같이 사용자 계정의 sendbirdId 가 null 값이라 발생한 오류였습니다 SendbirdGroupChannelInvitePayload userIds listOf account sendbirdId NullPointerException 발생 구현 코드를 변경한 게 아닌데도 단순히 TransactionalEventListener 에서 EventListener 로 변경했음에도 불구하고 왜 이런 오류가 발생하였을까요 코드의 구현 순서가 아닌 실제 동작하는 순서를 다시 한번 적어보겠습니다 유통사 계정을 생성합니다 1 유통사 계정을 생성합니다 11 유통사 계정 생성 이벤트를 발행합니다 12 샌드버드 사용자를 생성합니다 2 샌드버드 사용자 ID를 생성한 유통사 계정에 업데이트 합니다 3 유통사 계정 생성 이벤트를 받아 유통사의 모든 채팅방에 계정을 초대합니다 121 모든 주문채널에 계정을 초대합니다 1211 문의 채널에 계정을 초대합니다 1212 앞서 소개해 드린 순서와 조금 다른 부분을 볼 수 있을 텐데요 3번 항목인 유통사 계정을 생성한 이벤트를 발행 한 후 곧바로 이벤트를 소비하는 것이 아닌 7번 항목이었던 샌드버드 사용자 생성 과 8번 항목이었던 샌드버드 사용자 ID를 생성한 유통사 계정에 업데이트 하는 항목을 먼저 실행한 후 유통사 계정 생성 이벤트를 소비한다는 것을 알 수 있습니다 원인은 바로 TransactionalEventListener 의 동작 방식 때문입니다 TransactionalEventListener 문서 를 보면 아래와 같은 내용을 볼 수 있습니다 If a transaction is running the event is handled according to its TransactionPhase 즉 이벤트 리스너의 함수에 TransactionalEventListener 를 정의하면 해당 리스너의 함수는 정해진 Transaction 단계에 따라 수행되며 위 예시 코드에서는 OrderableVendorAccountFacadecreateAccount 함수에 Transactional 이 선언되어 있으므로 createAccount 함수가 끝난 시점에 ChatEventHandlerhandle 함수가 실행되는 것입니다 그래서 ChatEventHandlerhandle 함수의 어노테이션을 EventListener 로 바꿔주면 샌드버드 사용자를 생성 하고 샌드버드 사용자 ID를 생성한 유통사 계정에 업데이트 하는 로직이 실행되기 전에 이벤트가 소비되므로 유통사 계정의 샌드버드 ID를 조회하는 accountsendbirdId 코드에서 NullPointerException 이 발생하게 되는 것입니다 원인 통합테스트에서 검출되지 못한 버그로 인한 이슈는 위에서 소개해 드린 사례 말고도 많은데요 대부분 Hiberante Transaction 또는 Client의 Mocking으로 인해 발생한 이슈들로 모을 수 있었습니다 통합테스트를 위해 저희는 테스트 간의 데이터를 손쉽게 격리하고 Mock Bean들을 원활하게 생성하기 위해 아래와 같이 테스트를 위한 서버를 MOCK 모드로 실행하고 Transaction 내에서 실행되도록 설정해 두었습니다 SpringBootTest Import TestDatabaseConfiguration class Fixture class ApplicationEventPublisherSpyConfiguration class Transactional AutoConfigureMockMvc abstract class IntegrationTestBase BehaviorSpec 생략 MockkBean protected lateinit var s3BucketClient S3BucketClient MockkBean protected lateinit var chatClient ChatClient 그러다 보니 Transaction 밖에서의 Hibernate의 실행 동작을 테스트 환경에서 온전히 재현하기 어려웠습니다 그리고 모든 모듈에 대한 단위테스트가 되어있다 보니 통합테스트를 좀 더 편하게 하기 위해 API들을 추상화한 Client 클래스들을 Mocking 하였는데요 이로 인해 위 사례와 같이 실제 동작에서 발견할 수 있는 버그를 발견하지 못하는 사례가 생기게 된 것입니다 그래서 기능 테스트에서는 더 이상 MOCK 모드로 실행하는 것이 아닌 내장된 서버를 이용하여 테스트를 실행할 수 있도록 하고 MockBean 들을 모두 제거하여 테스트를 수행할 수 있도록 아래와 같이 베이스 클래스를 설정하였습니다 Import FunctionalTestConfig class SpringBootTest webEnvironment SpringBootTest WebEnvironment RANDOMPORT abstract class FunctionalTestBase FunSpec override fun extensions listOf SpringExtension private lateinit var mockServer ClientAndServer override suspend fun beforeSpec spec Spec val configuration Configuration configuration logLevel Level WARN mockServer ClientAndServer startClientAndServer configuration listOf SENDBIRDAPIPORT SLACKAPIPORT DATAGOVAPIPORT NCLOUDSENSAPIPORT NICEPAYWEBAPIPORT NICEPAYDATAAPIPORT KAKAOAPIPORT override suspend fun afterSpec spec Spec mockServer stop 생략 어떻게 전환 작업을 하였나요 앞선 사례를 통해 통합테스트 환경에서 발견하지 못한 버그들을 살펴보았는데요 본격적으로 기능 테스트로의 전환 이야기로 넘어가 보겠습니다 테스트 코드를 보여주는 것은 통합 테스트에서나 기능 테스트에서나 큰 틀에서는 차이가 없을 것이므로 어떠한 전략과 방법을 사용하여 기능 테스트를 수행하였는지 이야기해 보는 게 좋을 것 같습니다 기능 테스트 전환 가이드 언어 전환 프로젝트 때와 유사하게 기능 테스트로의 전환 작업은 긴 호흡을 가지고 진행해야 할 프로젝트였습니다 더욱이 언어 전환 프로젝트와 같이 제품 개발 프로젝트를 멈추고 진행하는 방식이 아니었기에 제품의 신규 개발 프로젝트와 병행해서 진행해야 했고 우선순위에 의해 일정이 종종 미뤄질 수 있었기에 일정을 정하기도 어려웠습니다 또한 구성원들이 테스트에 대한 이해도가 높아졌다고 하더라도 사람마다 이해도가 다르고 생소한 테스트 방식에 대한 어려움이 있을 수 있다고 생각했습니다 그래서 프로젝트 기간이 길어지더라도 기능테스트에 대한 작업 방법을 가이드하고 코드의 일관성을 유지하기 위해서 가이드 문서를 작성하여 구성원들에게 공유하였습니다 테스트 케이스 아래 그림은 이펙티브 소프트웨어 테스팅 에서 소개된 테스트 피라미드입니다 피라미드 상단으로 올라갈수록 복잡도는 올라가지만 현실성이 높아짐을 볼 수 있습니다 서버 언어를 전환하며 채택했던 테스트 전략에서와 같이 저희는 복잡한 비즈니스 요구사항에 대한 다양한 케이스들은 단위 테스트에서 모두 다루고 주요하거나 단위 테스트에서 발견하기 힘들다고 판단되는 케이스에 대해서 기능테스트를 작성하는 방식을 도입하였습니다 즉 보다 단순하게 테스트할 수 있는 단위 테스트에서 대부분의 비즈니스 로직을 테스트하고 실제 환경과 가장 유사하지만 테스트하기에 복잡한 기능 테스트에서는 전체적인 기능이 잘 수행되는지 혹은 단위 테스트만으로 불안하다고 판단되는 부분을 확인하기 위한 테스트 코드를 작성하였습니다 아래는 정산 데이터를 생성하는 기능에 대한 단위 테스트와 기능 테스트의 테스트 케이스입니다 단위 테스트는 각 모듈별로 여러 테스트 케이스가 존재하는 것을 볼 수 있지만 기능 테스트는 주요 기능에 대한 테스트 케이스만 존재하는 것을 볼 수 있습니다 정산 데이터 생성 단위 테스트들 중 테스트 케이스 일부 주문서 생성 기능 테스트 케이스 MockServer 통합 테스트에서 기능 테스트로 전환하는 여러 이유 중 하나가 바로 Client를 Mocking 함으로써 발견하지 못한 버그의 존재였습니다 그래서 기능 테스트에서는 최대한 외부 API를 그대로 사용하고자 하였는데요 AWS와 같이 저희가 관리하는 외부 API는 테스트를 위한 인프라를 구성해 둘 수 있었지만 그렇지 못한 외부 API도 존재하였습니다 그렇다고 이전과 같이 Client를 그대로 Mocking 하는 것은 좋지 않다고 생각했는데요 그래서 외부 API를 최대한 유사하게 사용하는 환경을 구성할 수 있는 MockServer 를 활용하기로 하였습니다 기능 테스트에서 MockServer를 사용하는 것에 대해 다소 논란이 있을 수 있겠지만 저희는 MockServer를 사용하게 되면서 아래와 같이 실제 외부 API를 사용할 때 발생할 수 있는 문제점을 해결할 수 있다는 부분이 더 매력적으로 다가와 MockServer를 채택하게 되었습니다 만약 외부 API가 다운된다면 테스트를 할 수 없음 외부 리소스를 생성하거나 수정하는 경우 외부 API로 검증하지 못하는 상황이 있음 외부 API에 데이터를 전달하기 위한 사전 조건이 너무 방대한 경우 혹은 불가능한 경우 외부 API에 테스트 데이터를 함부로 넣으면 안 되는 경우 사실 MockServer를 사용함으로써 블랙박스 테스트 의 장점을 많이 상쇄시킨다는 부분이 마음에 걸렸는데요 여러 고민을 해본 결과 블랙박스 테스트의 장점을 상쇄시키는 것이 외부 API를 복잡하게 사용함으로써 기능 테스트 코드 작성에 어려움을 겪는 것보다 낫다고 판단해서 결국 MockServer를 사용하기로 하였습니다 다만 테스트 코드에서 Mocking 부분을 최대한 추상화된 함수로 사용함으로써 테스트 코드를 복잡하지 않게 사용하도록 노력하였습니다 한편 왜 많은 Mock 서버 라이브러리 중 MockServer를 선택하였는지 궁금하실 수도 있겠는데요 MockServer를 선택한 이유는 단순히 저희가 이미 사용 중인 테스트 프레임워크인 Kotest에서 확장 기능 을 제공해 주었기 때문입니다 또한 저희는 Kotest의 가이드 문서와 같이 코드를 작성하지는 않고 최대한 기능 테스트 코드에서 Mocking에 대한 내용을 숨기기 위해 Base 클래스에서 MockServer 및 MockClient 를 생성하고 Helper 클래스를 통해 Mocking 코드를 최대한 추상화하여 사용하였습니다 Import FunctionalTestConfig class SpringBootTest webEnvironment SpringBootTest WebEnvironment RANDOMPORT abstract class FunctionalTestBase FunSpec override fun extensions listOf SpringExtension private lateinit var mockServer ClientAndServer override suspend fun beforeSpec spec Spec val configuration Configuration configuration logLevel Level WARN mockServer ClientAndServer startClientAndServer configuration listOf SENDBIRDAPIPORT SLACKAPIPORT NCLOUDSENSAPIPORT 생략 생략 TestConfiguration class FunctionalTestConfig 생략 Bean fun sendbirdApi MockServerClient localhost SENDBIRDAPIPORT Bean fun slackApi MockServerClient localhost SLACKAPIPORT Bean fun ncloudSensApi MockServerClient localhost NCLOUDSENSAPIPORT Bean fun mockery sendbirdApi MockServerClient slackApi MockServerClient ncloudSensApi MockServerClient 생략 Mockery return Mockery sendbirdApi slackApi ncloudSensApi 생략 fun Mockery createSendbirdUser sendbirdApi whenWithDefault HttpRequest request withMethod HttpMethod POST name withPath v3users respond template HttpTemplate TemplateType MUSTACHE statusCode 200 body userid jsonPathuseridjsonPathjsonPathResult trimIndent fun Mockery verifyCreateSendbirdUser userId String sendbirdApi verify HttpRequest request withMethod HttpMethod POST name withPath v3users withBody json userid userId trimIndent MatchType ONLYMATCHINGFIELDS test 매장과 유통사를 연결하면 샌드버드 계정이 생성된다 Given 생략 mockery createSendbirdUser When val actual clientBuilder token testHelper 점주 토큰 생성 manager id build executeQuery mutation variables extractValueAsObject connectOrderableVendor typeRef ConnectedOrderableVendor Then val actualStore testHelper 단일 매장 조회 store id actualStore managersSendbirdIds shouldHaveSize 1 val managerSendbirdId actualStore managersSendbirdIds first eventually duration 5 seconds mockery verifyCreateSendbirdUser managerSendbirdId 생략 Test Helper 클래스 앞에서도 언급하였지만 테스트를 작성하다 보면 기능을 수행하기 위한 값이나 상태를 만들기 위한 코드들이 필요합니다 특히 기능 테스트에서는 단위 테스트에 비해 준비 코드들이 상당히 필요할 수 있는데요 이러한 코드들을 모든 테스트에 하나하나 작성해 두기보다 Helper 클래스를 만들어서 사용하면 반복적인 코드를 상당히 줄일 수 있습니다 그리고 의미 있는 함수명을 사용한다면 좀 더 읽기 쉬운 테스트 코드를 작성할 수 있기도 합니다 아래 코드를 보시면 testHelper mockery 라는 변수로 사용되는 모듈을 볼 수 있을 텐데요 해당 모듈이 테스트를 위한 데이터를 생성해 주거나 검증을 위한 데이터를 가져오는 역할을 수행해줍니다 test 유통사 토큰으로 대량 메시지를 발송을 호출하면 대량 메시지 발송 이력이 저장되고 메시지가 발송된다 Given val orderableVendor testHelper 주문 가능한 거래처 생성 val orderableVendorAccount testHelper 주문 가능한 거래처 계정 생성 orderableVendor id val store testHelper 매장 생성 testHelper 점주 관리 매장 추가 store id testHelper 매장 주문 가능 유통사 연결 store id orderableVendor id val input SendBulkChatInput content content imageUrl imageUrl storeIds listOf store id val variables mapOf input to input 생략 When val actual clientBuilder token testHelper 주문 가능한 거래처 토큰 생성 orderableVendorAccount id build executeQuery mutation variables extractValueAsObject sendBulkChat typeRef SendBulkChat Then assertSoftly actual history it content shouldBe content it imageUrl shouldBe imageUrl val expectedStore testHelper 단일 매장 조회 store id val expectedGroupChannelUrl expectedStore getOrderChannelUrl orderableVendor id eventually 5 seconds mockery verifySendUserMessageToGroupChannel groupChannelUrl expectedGroupChannelUrl message content customType ORDERABLEVENDORANNOUNCEMENT sendbirdId orderableVendorAccount sendbirdId 생략 만약 Helper 클래스가 없다면 위에서 사용한 주문가능한거래처생성 함수와 같은 코드를 매번 작성해 주어야 해 상당한 코드 중복이 발생할 것입니다 fun 주문 가능한 거래처 생성 생략 OrderableVendor val facade context getBean OrderableVendorFacade class java val data OrderableVendorCreationData name name deliverableDayOfWeek deliverableDayOfWeek erpConfiguration ErpConfigurationCreateData erpType ErpType NOTSUPPORTED billPaymentConfigurationCreateData BillPaymentConfigurationCreateData usable false accountNumber null bank null accountHolder null virtualAccountBank null depositedMethod DepositMethod BYORDERABLEVENDOR feeRules listOf ecountErpConfigurationCreateData EcountErpConfigurationCreateData usable false companyCode null userId null apiCertKey null warehouseCode null businessInfo OrderableVendorBusinessInfo regNum regNum businessName businessName businessType businessType businessCondition businessCondition businessAddress businessAddress representative representative email email storageAddress storageAddress establishmentDate establishmentDate officials officials authenticationAttachments authenticationAttachments productInfo OrderableVendorProductInfo majorTradeStoreCategories majorTradeStoreCategories majorProductCategories majorProductCategories mainProducts mainProducts deliveryInfo OrderableVendorDeliveryInfo nextDayDeliveryDeadline nextDayDeliveryDeadline regions deliveryRegions preferredRegions preferredDeliveryRegions methods deliveryMethods deliveryTimeRange deliveryTimeRange paymentInfo OrderableVendorPaymentInfo availableMethods availablePaymentMethods intervals paymentIntervals minimumOrder minimumOrder inquiryInfo OrderableVendorInquiryInfo chatInquirable chatInquirable newStoreExtendable newStoreExtendable inqurableTime inqurableTime inqurableDayOfWeek inqurableDayOfWeek memo memo orderChannelWelcomeMessage orderChannelWelcomeMessage matchingEnabled matchingEnabled return facade createOrderableVendor data 테스트를 위한 Open EntityManager in View 기능 테스트를 수행하다 보면 리소스를 생성하는 API를 수행한 후 주어진 데이터로 리소스가 잘 생성되었는지 검증하기 위해 단언Assertion 시 데이터를 조회하게 됩니다 조회 API가 구현되어 있다면 해당 API를 사용하면 가장 이상적이겠지만 조회 API가 구현되어 있지 않는 경우에는 어쩔 수 없이 Service나 Repository를 이용하여 Entity를 조회해야 하는 경우가 발생합니다 이때 검증을 위해 조회한 Entity의 연관관계를 조회하면 아래와 같은 오류를 만나게 되는 경우가 있습니다 Hibernate에 한정된 이슈입니다 test 재무 담당자 권한과 거래일이 주어지면 대사 정보를 생성한다 Given 사전 데이터 생성 When clientBuilder token testHelper 재무 관리자 토큰 생성 build executeQuery mutation variables extractValueAsObject reconcile typeRef Reconcile Then val expected testHelper 단일 대사 조회 transactionDate assertSoftly expected it transactionDate shouldBe transactionDate it estimatedSettlementDate shouldBe LocalDate of 2023 3 7 it state shouldBe ReconciliationState SUCCESS it totalTransactionCount shouldBe 2 연관관계 조회 시 오류 발생 it preVendorSettlements shouldHaveSize 1 it totalTransactionAmount shouldBe 25000 toBigDecimal failed to lazily initialize a collection of role comspoqacartdomainreconciliationReconciliationtransactions could not initialize proxy no Session orghibernateLazyInitializationException failed to lazily initialize a collection of role comspoqacartdomainreconciliationReconciliationtransactions could not initialize proxy no Session at orghibernatecollectionspiAbstractPersistentCollectionthrowLazyInitializationExceptionAbstractPersistentCollectionjava635 at orghibernatecollectionspiAbstractPersistentCollectionwithTemporarySessionIfNeededAbstractPersistentCollectionjava218 at orghibernatecollectionspiAbstractPersistentCollectionreadSizeAbstractPersistentCollectionjava148 at orghibernatecollectionspiPersistentBagsizePersistentBagjava350 이유는 Transaction 밖에서 Lazy 하게 연관관계를 조회하려고 하면서 발생한 오류인데요 좀 더 자세히 알고 싶으시다면 Hibernate could not initialize proxy no Session 글을 봐주세요 테스트로 인해서 구현된 운영 코드를 바꿀 수 없으므로 테스트 코드에서 무언가 조치를 해야 할 필요가 있었습니다 해당 이슈에 대한 해결 방법으로 생각해 낸 것이 바로 OSIVOpen Session in View로 알려진 Spring의 Open EntityManager in View 입니다 Spring으로 Web Application을 개발하시는 개발자라면 OSIVOpen Sesison in View에 대해 잘 아실 것으로 생각합니다 OSIV 패턴은 Spring MVC에서 OpenEntityManagerInViewInterceptor 에 의해 적용되어야 하는데요 해당 클래스를 참고해서 아래와 같이 TestHelper 클래스에서 Entity를 조회한 후 연관관계를 사용할 때 오류가 발생하지 않도록 조치하였습니다 Target AnnotationTarget CLASS annotation class OpenEntityManager Aspect class OpenEntityManagerAspect EntityManagerFactoryAccessor Around withincomspoqacartfixtureOpenEntityManager fun openEntityManager pjp ProceedingJoinPoint Any logger debug Opening JPA EntityManager val emf EntityManagerFactory obtainEntityManagerFactory try val em EntityManager createEntityManager val emHolder EntityManagerHolder em TransactionSynchronizationManager bindResource emf emHolder catch ex PersistenceException throw DataAccessResourceFailureException Could not create JPA EntityManager ex try val result pjp proceed if result is PrimaryKeyEntity result loadAssociations return result finally val emHolder TransactionSynchronizationManager unbindResource emf as EntityManagerHolder logger debug Closing JPA EntityManager EntityManagerFactoryUtils closeEntityManager emHolder entityManager private fun PrimaryKeyEntity loadAssociations this class declaredMemberProperties forEach try it getter call this toString catch Exception TestComponent OpenEntityManager class TestHelper 생략 fun 단일 대사 조회 transactionDate LocalDate Reconciliation val facade context getBean ReconciliationFacade class java return facade reconcile transactionDate OpenEntityManagerAspect 클래스를 보시면 Spring의 AOP를 사용해서 OpenEntityManager 어노테이션이 선언된 클래스의 모든 함수에 OSIV를 적용한다는 것을 볼 수 있습니다 특히 loadAssociations 함수를 보면 조회한 Entity의 모든 연관관계를 조회한다는 것을 볼 수 있는데요 그 이유는 테스트를 수행하는 함수에서는 Transaction이 실행 중이지 않기 때문에 TestHelper 의 함수에서 모든 연관관계를 먼저 조회하여 테스트 함수에서 연관관계 조회 시 LazyInitializationException 이 발생하지 않도록 하기 위함이었습니다 이렇게 조치하면 Transactional 이 선언되어 있지 않은 테스트 코드에서도 운영 코드를 변경하지 않고 매번 Helper 클래스에서 연관관계를 명시적으로 조회하지 않고도 Entity의 연관관계를 손쉽게 조회할 수 있어 테스트 코드를 좀 더 손쉽게 작성할 수 있다는 장점이 있습니다 기능 테스트에서의 단언Assertion 통합 테스트에서 기능 테스트로 전환 시 가장 걱정했던 부분이 바로 테스트 케이스 간의 데이터 공유로 인한 간섭이었습니다 테스트 코드를 작성하는 데 하나의 테스트 케이스가 다른 테스트 케이스에 영향을 받지 않도록 하는 것이 이상적이지만 CI 환경에서 효율적이고 빠르게 테스트를 수행하기 위해서는 어쩔 수 없이 데이터베이스나 Message Queue와 같은 자원들은 공유할 수밖에 없었습니다 그러다 보니 통합 테스트에서는 Transaction을 테스트마다 실행시켜서 테스트 종료 후 Rollback 하는 형태로 테스트간 간섭을 회피하였는데요 기능 테스트에서는 테스트 케이스 함수에서 Transaction 사용으로 인한 문제점을 해결하려 하였기 때문에 통합 테스트의 방식을 사용할 수 없었습니다 매 테스트 코드가 실행될 때마다 데이터베이스를 초기화해 주는 스크립트를 실행시켜 보자는 의견도 나왔었지만 테스트가 실행될 때 준비 시간이 너무 늘어나는 이슈로 인해 해당 방법도 사용할 수 없었습니다 결국 기능 테스트에서는 데이터베이스나 Message Queue를 공유하되 각 테스트 케이스의 단언을 아래와 같이 다른 테스트 케이스에 영향을 받지 않게끔 작성하도록 하였습니다 통합 테스트 단언 예시 통합 테스트에서는 각 테스트마다 데이터가 격리되기 때문에 주문서를 생성한 후 전체 주문서를 조회해도 기대하는 주문서를 이용해서 단언을 수행할 수 있습니다 test 유통사를 생성한다 Given val orderableVendor testHelper 주문 가능한 거래처 생성 생략 When val actual clientBuilder token token build executeQuery mutation variables extractValueAsObject createOrderSheetorderSheet typeRef OrderSheetField Then val expected testHelper 전체 주문서 조회 expected shouldHaveSize 1 expected first id shouldBe actual id 기능 테스트 단언 예시 기능 테스트에서는 테스트마다 데이터가 격리되지 않기 때문에 각 테스트 케이스에서 생성한 유통사를 이용하여 기대하는 주문서를 조회한 후 단언을 수행하도록 하여 테스트의 거짓양성이 발생하지 않도록 하였습니다 test 유통사를 생성한다 Given val orderableVendor testHelper 주문 가능한 거래처 생성 생략 When val actual clientBuilder token token build executeQuery mutation variables extractValueAsObject createOrderSheetorderSheet typeRef OrderSheetField Then val expected testHelper 유통사의 주문서 목록 조회 orderableVendor id expected shouldHaveSize 1 expected first id shouldBe actual id 비동기 코드 검증 테스트의 단언Assertion의 연장선으로 통합 테스트에서 기능 테스트로 전환 시 고민했던 부분이 비동기 코드의 검증이었습니다 백엔드에서는 주문서 생성 시 슬렉 메시지 전송과 같은 주요 로직이 아닌 부가적인 로직을 처리할 때나 처리 효율성을 이유로 비동기적으로 서버 요청을 처리해야 할 때 Async 를 활용하고 있습니다 Async 와 관련한 자세한 내용은 Creating Asynchronous Methods 글을 참고해 주세요 통합 테스트에서는 Mocking을 이용하여 호출 여부만 판단하는 형태로 테스트 코드를 작성했었는데요 그러다 보니 이벤트 처리에 대한 대부분의 코드가 대부분 단위테스트로만 검증되고 있었습니다 그래서 비동기 코드가 최종적으로 어떻게 통합되어 수행되는지 검증하지 못한다는 단점이 있었는데요 그래서 기능 테스트로 전환하면서 비동기적인 코드가 끝까지 실행되는지를 테스트하여 해당 기능에 대한 안정성을 좀 더 높이고자 하였습니다 하지만 비동기적으로 실행되는 코드를 검증하는 것은 동기적으로 실행되는 코드보다 복잡할 수 있는데요 저희는 아래와 같은 선택지에서 고민하였습니다 Threadsleep 다소 아름답지 못한 방식이지만 가장 단순하게 시도해 볼 수 있는 코드입니다 test 주문서를 생성하면 주문 메시지를 발송한다 Given val input CreateOrderSheetInput val variables mapOf input to input When val actual clientBuilder token token build executeQuery mutation variables extractValueAsObject createOrderSheet typeRef CreateOrderSheet Then val expected testHelper 유통사의 주문서 목록 조회 orderableVendor id expected shouldHaveSize 1 expected first id shouldBe actual id Thread sleep 1000 mockery verifySendUserMessageToGroupChannel 위 코드대로라면 비동기 코드가 언제 실행되든지 간에 테스트는 최소 1초 이상 실행될 것입니다 거기다 만약 이벤트가 1초 이상 걸린다면 테스트는 실패하게 되겠죠 테스트 코드를 작성하는 중에 제대로 테스트 코드를 작성하고 있는지 확인하기 위해 임시로 코드를 넣어볼 순 있겠지만 Threadsleep 을 그대로 사용하는 것은 좋아 보이지 않습니다 SyncTaskExecutor 다음 방법으로는 SyncTaskExecutor 를 활용하는 것입니다 SyncTaskExecutor 는 Async 로 선언된 코드를 동기적으로 수행되도록 해줍니다 문서에도 쓰여있다시피 주로 테스트를 위해 사용됩니다 테스트 설정에서 아래와 같이 코드를 작성하면 사용할 수 있습니다 TestConfiguration EnableAsync class AsyncConfig AsyncConfigurer override fun getAsyncExecutor Executor return SyncTaskExecutor 이렇게 설정하면 이제는 더이상 Threadsleep1000 과 같은 코드를 넣지 않고도 비동기 기능을 검증할 수 있게 됩니다 test 주문서를 생성하면 주문 메시지를 발송한다 Given val input CreateOrderSheetInput val variables mapOf input to input When val actual clientBuilder token token build executeQuery mutation variables extractValueAsObject createOrderSheet typeRef CreateOrderSheet Then val expected testHelper 유통사의 주문서 목록 조회 orderableVendor id expected shouldHaveSize 1 expected first id shouldBe actual id mockery verifySendUserMessageToGroupChannel 하지만 해당 설정에도 문제점이 존재하였는데요 저희는 부가적인 로직예를 들어 주문서 생성 알림을 위한 메시지 전송에서 발생하는 오류가 주요 로직예를 들어 주문서 생성에 영향을 미치지 않았으면 하였는데요 부가적인 로직을 비동기 함수로 처리하게 되면 이러한 요구사항을 충족시킬 수 있었습니다 그래서 만약 sendUserMessageToGroupChannel 함수에서 오류가 발생하더라도 주문서 생성은 문제없이 동작하는 것입니다 그러나 SyncTaskExecutor 를 사용하면 이러한 요구사항을 충족시키지 못합니다 부가적인 로직에서 발생한 오류가 전파되어 주요 로직에도 영향을 미치기 때문입니다 운영환경과 테스트환경에 차이가 있는 것은 어느 정도 불가피하다지만 이러한 주요 요구사항을 충족하지 못하는 부분은 중대하다고 판단해서 SyncTaskExecutor 를 사용하지 않기로 하였습니다 eventually 결국 저희는 Kotest에서 제공하는 Eventually 를 사용하기로 하였는데요 Eventually 는 실제 환경과 동일하게 테스트 환경을 구성함과 동시에 Threadsleep1000 을 사용하지 않도록 하는 가장 손쉬운 방법을 제공해 주었습니다 Eventually 는 제한된 시간 내에 기대하는 비동기 코드가 실행되는지 가장 짧은 시간 내에 알려줍니다 그래서 Threadsleep1000 을 사용했을 때처럼 무조건 지정된 시간을 기다리지도 않고 비동기 코드 단언을 위한 복잡한 코드를 작성하지도 않아도 되었습니다 test 주문서를 생성하면 주문 메시지를 발송한다 Given val input CreateOrderSheetInput val variables mapOf input to input When val actual clientBuilder token token build executeQuery mutation variables extractValueAsObject createOrderSheet typeRef CreateOrderSheet Then val expected testHelper 유통사의 주문서 목록 조회 orderableVendor id expected shouldHaveSize 1 expected first id shouldBe actual id eventually 5 seconds mockery verifySendUserMessageToGroupChannel 전환 시 이슈는 없었나요 앞서 말씀드렸지만 처음부터 기능 테스트로 테스트 코드를 작성하지 않고 통합 테스트로 테스트 코드를 작성할 만큼 기능 테스트에 대한 난이도에 대한 우려가 있었습니다 아니나 다를까 기능테스트를 전환하면서 수많은 이슈를 겪게 되었는데요 모두 소개해 드리면 좋겠지만 내용이 너무 길어질 수 있으므로 저희가 겪었던 대표적인 이슈들을 소개하고 어떻게 해결하였는지 이야기해 보겠습니다 Flaky tests 저희는 CIContinuous Integration 도구로 CircleCI 를 사용합니다 CircleCI에서는 Insights라는 기능을 통해 테스트 케이스가 간헐적으로 실패하는 테스트를 알려줍니다 CircleCI 문서의 Flaky tests 를 참고해 주세요 기능테스트로 전환하면서 CI에서 Flaky tests의 빈도가 증가하였는데요 앞서 말씀드린 바와 같이 기능 테스트에서는 테스트간 상태 격리가 되지 않아 개발자의 실수 탓에 간헐적으로 실패가 발생하는 것이었습니다 기능 테스트에서의 단언 부분에서 말씀드렸다시피 최대한 테스트 간에 영향을 받지 않게끔 코드를 작성함에도 간헐적인 테스트의 거짓양성이 발생할 수 있는 것은 어쩔 수 없다고 생각합니다 그래서 저희는 완벽하게 간헐적인 테스트 실패를 막으려 하기보다 아래와 같이 CI의 Flaky tests 리포트를 자주 모니터링하면서 최대한 불안정한 테스트를 줄이도록 노력하고 있습니다 MockServer Response Template 테스트 코드를 작성할 때 테스트를 어렵게 하는 요인 중 하나가 바로 현재시간 Random 데이터 생성 등 테스트 대상 내에서 생성하는 무작위 값이 존재할 때입니다 좀 더 테스트하기 쉬운 코드를 작성하기 위해서 단위 테스트에서는 의존주입 매개변수로 추출 등과 같은 기술을 이용하지만 기능테스트에서는 이마저도 활용할 수 없는 경우가 많습니다 그래서 기능테스트에서는 검증하기 힘든 값들은 이미 단위 테스트에서 잘 검증했다는 가정하에 과감히 생략하기도 합니다 하지만 이마저도 주요 로직에 포함되거나 모듈 간에 통합하는 부분에서 테스트가 필요한 경우 생략하지 못하는 상황이 존재합니다 저희는 MockServer를 활용하면서 해당 이슈들을 겪었는데요 대표적인 사례만 소개하고 넘어가 보겠습니다 아래 코드는 매장과 유통사를 연결하는 기능에 대한 테스트입니다 test 관리자 권한으로 유통사와 매장을 연결하면 매장과 유통사가 연결된다 Given val orderableVendor testHelper 주문 가능한 거래처 생성 val store testHelper 매장 생성 val input ConnectStoreOrderableVendorInput val variables mapOf input to input mockery getSendbirdUser 생략 When val actual clientBuilder token testHelper 관리자 토큰 생성 build executeQuery mutation variables extractValueAsObject connectStoreOrderableVendor typeRef ConnectedStoreOrderableVendor Then 생략 eventually 5 seconds mockery verifyCreateSendbirdUser createdSendbirdId MockerygetSendbirdUser 함수를 보면 아래와 같이 외부 API를 Mocking하고 있는데요 fun Mockery getSendbirdUser sendbirdApi whenWithDefault HttpRequest request withMethod HttpMethod GET name withPath v3users respond HttpResponse response withStatusCode 200 withBody json userid generateId nickname generateString trimIndent userid 를 랜덤한 값으로 Mocking 하게 되면서 테스트가 실패하거나 검증하지 못하는 상황이 발생하였습니다 그래서 저희는 랜덤한 값을 생성하여 전송하더라도 운영 코드 변경 없이 테스트가 잘 수행되도록 할 방법을 모색하기 시작하였습니다 첫 번째는 MockerygetSendbirdUser 함수에 매개변수를 추가하는 방법이 논의되었습니다 fun Mockery getSendbirdUser userId String sendbirdApi whenWithDefault HttpRequest request withMethod HttpMethod GET name withPath v3users respond HttpResponse response withStatusCode 200 withBody json userid userId nickname generateString trimIndent 가장 직관적이고 손쉽게 문제를 해결할 방법 같아 보이지만 API 서버 내부에서 userId 를 랜덤하게 생성하는 경우에는 해당 값을 매개변수로 전달할 수 없기 때문에 해결 방법으로 사용할 수 없었습니다 두 번째 방법으로 MockServer의 Response Template 을 활용하는 방법을 모색하였습니다 Response Template에는 여러 가지 포맷들이 있는데요 그중 저희는 Mustache Response Templates 을 사용하였습니다 fun Mockery getSendbirdUser sendbirdApi whenWithDefault HttpRequest request withMethod HttpMethod GET name withPath v3usersuserId withPathParameters param userId respond template HttpTemplate TemplateType MUSTACHE statusCode 200 body userid requestpathParametersuserId0 nickname generateId trimIndent 위 코드를 보시면 requestpathParametersuserId0 부분이 보이실 텐데요 해당 값은 withPathv3usersuserId 의 userId 값을 그대로 반환하도록 하는 문법입니다 이를 통해 위에서 작성한 테스트가 실패하지 않고 올바르게 검증되도록 할 수 있었고 결국 저희는 두 번째 방법을 사용하기로 하였습니다 Message Throttling 청구수납 서비스 개발기 에서 Message Throttling과 관련한 이야기를 다루었었는데요 Bucket4j 의 Message Throttling을 사용하기 위해서는 데이터베이스와 Message Queue가 필요합니다 앞서 말씀드린 바와 같이 기능테스트에서는 데이터베이스와 Message Queue를 공유해서 사용하고 있는데요 이에 따라 Throttling 된 메시지를 전송할 때 eventually 를 사용해 검증하지만 메시지 전송 단언Assertion이 되지 않는 이슈가 발생하였습니다 특이한 점은 단일 테스트 케이스를 실행해서 테스트하는 경우에는 성공하지만 전체 테스트 케이스를 실행시키면 실패한다는 것이었습니다 원인은 바로 Message Throttling이 문제였었는데요 하나의 테스트 케이스만 실행하는 경우 Throttling 대기열에 쌓여있는 메시지가 없으므로 eventually 로 검증 시 제한된 시간 내 잘 검증이 되는 것을 볼 수 있었습니다 하지만 전체 테스트를 실행하는 경우 Throttling 대기열에 다수의 테스트 케이스 메시지들이 쌓이게 되고 Throttling 되어 소비되기 때문에 eventually 로 검증을 시도하더라도 제한된 시간 내 단언에 성공하지 못해 테스트가 실패하는 경우가 발생한 것입니다 해당 이슈를 발견하기까지 상당히 애를 먹었네요 생각해 보면 Message Throttling을 구현한 이유가 외부 API의 제약조건 때문이었는데요 이러한 외부요인을 회피하기 위해 저희는 MockServer를 활용하고 있으므로 Message를 Throttling 할 필요가 없습니다 그래서 저희는 아래와 같이 Throttling이 걸려있는 Bucket 설정을 모두 Throttling이 걸리지 않도록 변경하여 문제를 해결했습니다 운영 환경 설정 Configuration class Bucket4jConfig Bean fun bucketProxyManager dataSource DataSource PostgreSQLadvisoryLockBasedProxyManager Long return PostgreSQLadvisoryLockBasedProxyManager Long Long SQLProxyConfiguration builder build dataSource Bean fun sendbirdUserMessageBucket bucketProxyManager PostgreSQLadvisoryLockBasedProxyManager Long BucketProxy val key 1003L val bucketConfiguration BucketConfiguration builder addLimit Bandwidth simple 5 Duration ofSeconds 1 1초에 5회로 Throttling build return bucketProxyManager builder build key bucketConfiguration 생략 테스트 환경 설정 TestConfiguration class Bucket4jConfig private val unlimited Bandwidth Bandwidth simple Long MAXVALUE Duration ofNanos Long MAXVALUE Bean fun bucketProxyManager dataSource DataSource PostgreSQLadvisoryLockBasedProxyManager Long return PostgreSQLadvisoryLockBasedProxyManager Long Long SQLProxyConfiguration builder build dataSource Bean fun sendbirdUserMessageBucket bucketProxyManager PostgreSQLadvisoryLockBasedProxyManager Long BucketProxy val key 1003L val bucketConfiguration BucketConfiguration builder addLimit unlimited Throttling 설정하지 않음 build return bucketProxyManager builder build key bucketConfiguration 생략 마무리 지금까지 저희 백엔드 챕터에서 기능 테스트로 전환 시 사용했던 여러 가지 방법들을 알아보았습니다 상황을 보다 이해가 잘되도록 하려다 보니 다소 세세한 부분까지 다루게 되었는데요 기능 테스트를 전환할 때 어떠한 애로사항들이 있는지 해당 애로사항들을 어떻게 풀어나갈 수 있는지와 같은 넓은 관점에서 바라봐 주시면 좋을 것 같습니다 모두의 노력 덕분에 저희는 올해 통합 테스트 코드를 모두 제거하고 온전히 기능 테스트로만 전체 기능을 테스트할 수 있게 되었습니다 다만 여전히 기능테스트에 대한 개선할 점들은 많이 있어 보이네요 모쪼록 이번 이야기가 여러분의 테스트 코드 작성에 조금이나마 도움이 되었길 바라며 기능 테스트를 작성하면서 다시 또 재미있는 이야깃거리가 있다면 소개해 드리는 글로 찾아뵙도록 하겠습니다 긴 글 읽어주셔서 감사합니다 스포카에서는 식자재 시장을 디지털화한다 라는 슬로건 아래 매장과 식자재 유통사에 도움되는 여러 솔루션들을 개발하고 있습니다 더 나은 제품으로 세상을 바꾸는 성장의 과정에 동참 하실 분들은 채용 정보 페이지를 확인해주세요,https://spoqa.co.kr/wp-content/uploads/2022/10/logo_spoqa-1.svg,https://spoqa.github.io/2023/10/20/functional-testing-converting-story.html
@jocoding,"AI 뉴스 - 엔비디아 근황, 미국 vs 중국 AI 전쟁, AI 정치 성향, 딥페이크 합법화, 키보드 해킹, 시뮬레이션 오픈소스 공개 등",https://img.youtube.com/vi/RQEwsrNGOlI/0.jpg,https://www.youtube.com/watch?v=RQEwsrNGOlI
ChatGPT의 전두엽(장기기억 저장소)으로 각광받고 있는 Vector DB에 대해 알아보자,벡터 데이터베이스란 벡터 데이터베이스는 방대한 양의 고차원 데이터를 벡터 형태로 최적화 하여 보관하고 쿼리하기 위해 특화된 DB 벡터는 서로 다른 특성이나 품질을 기반으로 개체를 설명하는 수학적 데이터 표현입니다 각 벡터는 단어나 그림과 같은 단일 데이터 요소를 나타내며 여러 특성을 설명하는 값 모음으로 구성됩니다 이러한 변수를 기능 또는 치수라고도 합니다 예를 들어 그림은 픽셀 값의 벡터로 표현될 수 있지만 전체 문장은 단어 임베딩의 벡터로 표현될 수 있습니다 벡터 데이터베이스는 인덱싱 전략을 사용하여 특정 쿼리 벡터와 유사한 벡터를 쉽게 찾을 수 있습니다 이는 기계 학습 과 같은 경우에 특히 유익합니다 유사한 데이터 포인트를 발견하거나 제안을 생성하기 위해 유사성 검색이 자주 사용되기 때문입니다 AI 어플리케이션들은 Vector Embeddings에 의존 임베딩은 AI 모델에 의해 생성되며 많은 수의 속성피쳐가 있어서 관리하기가 어려움 AI 및 ML에서 이 피쳐들은 패턴 관계 및 기본 구조를 이해하는데 필수적인 데이터의 다양한 디멘젼들을 표현 벡터DB를 통해서 AI에 시맨틱 정보 검색 장기 메모리 등의 고급 기능들을 구현 가능 임베딩 모델을 통해서 인덱싱할 콘텐츠의 벡터 임베딩을 생성 벡터 임베딩들을 벡터DB에 삽입 임베딩이 어디에서 생성되었는지 오리지널 콘텐츠에 대한 레퍼런스를 포함 어플리케이션이 쿼리를 하면 같은 임베딩 모델을 이용하여 쿼리에 대한 임베딩을 생성하고 이 임베딩으로 DB를 검색해서 비슷한 벡터 임베딩을 찾음 이 임베딩들은 오리지널 콘텐츠에 연결되어 있음 벡터 데이터베이스의 내부 작동 벡터 데이터베이스는 다음과 같은 기술로 생성된 고차원 벡터를 저장하고 인덱싱하는 데 사용됩니다 이러한 벡터는 임베딩 기술을 통해 중요한 정보를 유지하면서 저차원 공간으로 변환되는 복잡한 데이터 항목의 수치 표현입니다 따라서 벡터 데이터베이스는 벡터 임베딩의 특정 구조를 수용하도록 구축되었으며 인덱싱 알고리즘을 사용하여 쿼리 벡터와의 유사성을 기반으로 벡터를 효과적으로 검색하고 검색합니다 어떻게 작동하는가 벡터 데이터베이스는 ANNApproximate Nearest Neighbor 검색에 모두 참여하는 서로 다른 알고리즘의 조합을 사용합니다 이러한 알고리즘은 해싱 양자화 또는 그래프 기반 검색을 통해 검색을 최적화합니다 벡터 데이터베이스는 대략적인 결과를 제공 주요 트레이드 오프 정확도와 속도결과 정확도 쿼리 속도 반비례 벡터 데이터베이스에 대한 일반적인 파이프라인 Indexing 벡터 데이터베이스는 PQ LSH 또는 HNSW와 같은 알고리즘을 사용하여 벡터를 인덱싱합니다 이 단계는 더 빠른 검색을 가능하게 하는 데이터 구조에 벡터를 매핑합니다 Querying 벡터 데이터베이스는 가장 가까운 이웃을 찾기 위해 인덱스 쿼리 벡터를 데이터 세트의 인덱스 벡터와 비교합니다 해당 인덱스에서 사용하는 유사성 메트릭 적용 Post Processing 경우에 따라 벡터 데이터베이스는 데이터 세트에서 가장 가까운 최종 이웃을 검색하고 사후 처리하여 최종 결과를 반환합니다 이 단계에는 다른 유사성 척도를 사용하여 가장 가까운 이웃의 순위를 재지정하는 작업이 포함될 수 있음 벡터 인덱스 생성에서 사용하는 알고리즘 Random Projection 무작위 투영의 기본 아이디어는 무작위 투영 행렬을 사용하여 고차원 벡터를 저차원 공간에 투영하는 것입니다 난수 행렬을 만듭니다 행렬의 크기는 우리가 원하는 목표 저차원 값이 될 것입니다 그런 다음 입력 벡터와 행렬의 내적을 계산하여 원래 벡터보다 차원이 적지만 유사성을 유지하는 투영 행렬을 생성합니다 Product Quantization 벡터 임베딩과 같은 고차원 벡터에 대한 손실 압축 기술인 제품 양자화PQ입니다 원본 벡터를 가져와서 더 작은 청크로 나누고 각 청크에 대한 대표 코드를 생성하여 각 청크의 표현을 단순화한 다음 유사성 작업에 중요한 정보를 잃지 않고 모든 청크를 다시 결합하는 것 Loclitysensitive hashing LSHLocalitySensitive Hashing는 근사 최근접 이웃 검색 컨텍스트에서 인덱싱하는 기술입니다 속도에 최적화되어 있으면서도 대략적이고 포괄적이지 않은 결과를 제공합니다 Hierarchical Navigable Small World HSNW HSNW는 트리의 각 노드가 벡터 세트를 나타내는 계층적 트리와 같은 구조를 생성합니다 노드 사이의 모서리는 벡터 간의 유사성을 나타냅니다 유사성 측정 코사인 유사성 벡터 공간에서 두 벡터 간의 각도의 코사인을 측정합니다 범위는 1에서 1까지이며 여기서 1은 동일한 벡터를 나타내고 0은 직교 벡터를 나타내고 1은 정반대의 벡터를 나타냅니다 유클리드 거리 벡터 공간에서 두 벡터 사이의 직선 거리를 측정합니다 범위는 0에서 무한대까지이며 여기서 0은 동일한 벡터를 나타내고 값이 클수록 점점 더 다른 벡터를 나타냅니다 내적 두 벡터 크기의 곱과 두 벡터 사이 각도의 코사인 값을 측정합니다 범위는 에서 까지이며 양수 값은 같은 방향을 가리키는 벡터를 나타내고 0은 직교 벡터를 나타내고 음수 값은 반대 방향을 가리키는 벡터를 나타냅니다 메타데이터를 통한 필터링 Postfiltering 벡터 검색 후에 메타데이터 필터링이 수행됩니다 이렇게 하면 모든 관련 결과를 고려하는 데 도움이 될 수 있지만 검색이 완료된 후 관련 없는 결과를 필터링해야 하므로 추가 오버헤드가 발생하고 쿼리 프로세스 속도가 느려질 수도 있습니다 Prefiltering 벡터 검색 전에 메타데이터 필터링이 수행됩니다 이렇게 하면 검색 공간을 줄이는 데 도움이 되지만 시스템에서 메타데이터 필터 기준과 일치하지 않는 관련 결과를 간과할 수도 있습니다 또한 광범위한 메타데이터 필터링으로 인해 계산 오버헤드가 추가되어 쿼리 프로세스가 느려질 수 있습니다 데이터베이스 관련 성능 및 내결함성 샤딩 Replication 모니터링 액세스 제어 백업 및 컬렉션 API 및 SDK Vector Index 와 Vector DB의 차이점 FAISSFacebook AI Similarity Search 같은 벡터 인덱스도 벡터 임베딩 검색을 개선하지만 DB의 기능을 가지고 있지는 않음 Vector DB는 여러가지 장점을 가짐 데이터 관리 기능 데이터의 삽입 삭제 갱신이 쉬움 메타데이터 저장 및 필터링 각 벡터에 대한 메타데이터 저장이 가능 확장성 분산 및 병렬처리 기능을 제공 실시간 업데이트 지원 백업 및 컬렉션 기능일부 인덱스만 골라서 백업 에코시스템 연동 ETLSpark 분석도구Tableau Segment 시각화Grafana 등과 연동 AI 도구와의 연동LangChain LlamaIndex ChatGPT Plugins 데이터 보안 및 접근 권한 관리 요약 NLP 컴퓨터 비전 및 다른 AI 어플리케이션에서 벡터 임베딩이 폭발적으로 성장하면서 벡터 데이터베이스가 등장 프로덕션 시나리오에서 벡터 임베딩을 관리할 때 발생하는 문제점을 해결하기 위해 특수하게 만들어진게 벡터 데이터베이스 기존의 스칼라 기반 데이터 베이스 및 스탠드얼론 벡터 인덱스에 비해 상당한 이점을 제공 Colab 실습 코드 httpscolabresearchgooglecomdrive1iIZBCvA1HIAIToxCbyKZLt5XG7VjhJsuspsharingscrollToH7mtGc941Z1i httpscolabresearchgooglecomgistIvanCampos909cc104444f0ce950b7f991bcc016c6vectorpineconeopenaiipynbscrollToDSFAZXvsQow1 httpscolabresearchgooglecomgistIvanCampos715908e57fc1c1a6acd374e31f8c8aa9vectorchromaopenaiipynbscrollToGJe9ELXnrITV httpscolabresearchgooglecomgistIvanCampose595371a66d96811116e9a444a63816evectorlangchainopenaiipynb 참고자료 httpshashdorkcomko벡터데이터베이스 httpsnewshadaiotopicid9147 httpswwwpineconeiolearnvectordatabase What is a Vector Database Pinecone httpswwwtrychromacom AI 이미지 검색 엔진 만들기 벡터 데이터베이스 설명과 Chroma DB 튜토리얼 Vector Databases as Memory for your AI Agents 인공지능님이 장기기억장치vector db를 획득하셨습니다 httpstowardsdatasciencecommilvuspineconevespaweaviatevaldgsiwhatunitesthesebuzzwordsandwhatmakeseach9c65a3bd0696 httpswwwredditcomrMachineLearningcomments12m9pg0alternativestopineconevectordatabasesdonetapautotrue httpssourceforgenetsoftwarecompareMyScalevsPineconevschroma,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=164964&boardType=techBlog&searchData=&page=&subIndex=
"CES 불참한 애플의 '장외공격'…""비전프로 헤드셋 다음 달 2일 출시""","세계 최대 가전·IT 전시회인 CES 2024 개막을 앞두고 애플이 행사 비전프로 출시 소식을 알리면서, 메타버스와 관련된 AI 하드웨어에 대한 관심과 경쟁이 한층 달아오를 전망이다.
8일(현지시간) CNBC 등에 따르면 애플은 이날 비전프로 출시일을 공개하고, 오는 19일 오후 5시부터 사전 예약을 받는다고 발표했다.
비전프로 헤드셋은 컴퓨터에 사용되는 것과 같은 애플의 M2 칩으로 구동된다.
애플은 이를 위해 ‘비전OS’라는 새로운 운영 체제를 개발했다.
애플은 새로운 헤드셋을 통해 소비자가 게임 및 비디오 콘텐츠를 경험하는 방식을 바꾸는 것을 목표로 하고 있다.
애플 측은 이날 “사용자들이 100피트(3m) 너비로 느껴지는 가상현실 화면에서 애플TV+ 등 여러 플랫폼의 영상을 볼 수 있을 것”이라고 설명했다.
일각에선 이번 비전프로 출시로 인해 메타의 MR 헤드셋 퀘스트3와 경쟁 구도를 형성하면서 관련 시장에 대한 관심이 커질 것으로 보고 있다.",https://imgnews.pstatic.net/image/015/2024/01/09/0004934329_001_20240109071901019.jpg?type=w647,https://n.news.naver.com/mnews/article/015/0004934329?sid=105
'460만원'…애플 MR 헤드셋 '비전프로' 내달 2일 美 출시,"애플은 8일(현지시간) 보도자료를 내고 비전 프로를 다음 달 2일 미국 내 애플스토어와 애플스토어 온라인에서 판매한다고 밝혔다.
비전 프로는 애플이 2014년 애플워치 이후 사실상 처음 내놓은 완전히 새로운 범주의 신제품이다.",https://imgnews.pstatic.net/image/215/2024/01/09/A202401090010_1_20240109054101303.jpg?type=w647,https://n.news.naver.com/mnews/article/215/0001142747?sid=105
LoL 2024 로드맵 공개… 이스포츠 '전설의 전당' 첫 선보여,"라이엇 게임즈가 PC MOBA(다중사용자 온라인 전투 아레나) 게임 ‘리그 오브 레전드(LoL)’의 2024 시즌 주요 업데이트 계획을 5일(미 현지시각) 발표했다.
LoL 2024 시즌 공식 이미지 / 라이엇 게임즈 제공
라이엇 게임즈는 LoL 기반 장편 애니메이션 시리즈 ‘아케인(ARCANE)’ 시즌 2의 프리뷰 영상과 관련 인게임 콘텐츠 도입 계획도 공개했다.
LoL 이스포츠 전설의 전당은 게임, 스포츠, 커뮤니티에 긍정적인 영향을 끼친 인물을 공식 선정하고 그들의 행보를 기릴 예정이다.
사상 첫 LoL 이스포츠 전설의 전당의 주인공을 선발하기 위해 글로벌 이스포츠 전문가들을 초빙하여 투표를 진행한다.",https://imgnews.pstatic.net/image/366/2024/01/08/0000960553_001_20240108094801440.png?type=w647,https://n.news.naver.com/mnews/article/366/0000960553?sid=105
(tmux) 터미널을 효율적으로 사용하기 (1/2),command line 명령을 사용할 때 터미널에서 여러 기능들을 사용해야 할 때가 있다 예를 들어 여러 윈도우창을 띄워놓고 필요에 따라 옮긴다던가 하나의 윈도우을 상하 혹은 좌우로 구분하여 나눠서 사용하는 경우가 있다 보통은 명령어를 여러 디렉토리를 옮겨가며 작업하기 때문에 디렉토리 마다 윈도우를 만들어 사용한다 혹은 포그라운드로 프로세스를 띄워 출력되는 로그를 확인하고 다른 윈도에서 작업하는 경우도 있다 위와 같은 기능을 제공하는 툴에는 tmux 라는 sw가 있다 일반적으로 linux 에는 기본으로 설치되어 있고 mac 에서는 쉽게 설치할 수 있으므로 쉽게 활용할 수 가 있다 1 세션 관리 세션 만들기 tmux 는 세션 단위로 구분하여 관리한다 자신만의 새로운 세션을 만들어 독립으로 사용할 수 있다 tmux new s ahnsk ahnsk 이라는 새로운 세션session이 생성되면서 1zsh 라는 윈도우window 1개가 기본적으로 생성되었다 exit exit 는 현재의 윈도우를 삭제한다 지금은 세션에 1개의 윈도우 밖에 없기 때문에 윈도우가 삭제되면 해당 세션도 삭제된다 command prefix tmux 에서는 vi 처럼 명령모드를 사용할 수 있다 Ctrl b control 키와 b 키를 동시에 누름를 입력한 이후에 명령어를 입력하면 되는데 명령 모드를 알려주는 이 키 조합을 command prefix 라고 한다 줄여서 앞으로는 prefix 라고 한다 prefix t 를 누르면 화면에 시간에 표시된다 Detaching 과 Attaching exit 는 윈도우를 삭제경우에 따라서는 세션까지도 삭제 하기 때문에 이전의 세션과 윈도우를 계속 유지 시키면서 tmux에서 빠져나오고 싶을 때도 있다 이 때 사용해야할 기능이 detaching 기능이다 top prefix d 를 입력하여 detaching 한다 detached from session ahnsk 가 출력되고 원래의 터미널 창으로 빠져나온 것이 확인 된다 d 옵션으로 새로운 세션을 만들고 바로 detaching 할 수 도 있다 tmux new s dummy d 세션을 조회하여 기존에 만든 세션의 리스트를 확인할 수 있다 tmux ls output ahnsk 1 windows created Sat Jan 14 145109 2023 dummy 1 windows created Sat Jan 14 152539 2023 기존의 만든 ahnsk 세션으로 들어가고 싶으면 attach 명령을 쓰면 된다 tmux attach t ahnsk 세션 삭제 killsession 옵션으로 세션을 삭제할 수 있다 tmux killsession t ahnsk tmux killsession t dummy 2 윈도우 관리 윈도우 만들기 session 을 만들면 새로운 윈도우도 기본으로 생성된다고 했다 이 때 n 옵션을 사용하여 생성되는 윈도우에 이름을 넣을 수 있다 tmux new s ahnsk n shell prefix c 명령으로 새로운 윈도우를 만들 수 있다 이렇게 새로 만든 윈도우에 top 명령을 실행해 보자 윈도우 이름 변경 첫번째 윈도우의 이름은 shell 이고 두번째 top 이 실행되고 있는 윈도우의 이름은 top 이다 top 이 실행되고 있으므로 두번째 윈도우 이름을 process 로 변경해 보자 prefix 로 윈도우 이름을 변경할 수 있다 이름을 넣은 뒤에 enter 를 치면 된다 윈도우 이동 작업 윈도우를 아래 명령으로 옮겨 다닐 수 있다 prefix n 현재 윈도우 다음next 윈도우로 이동하기 prefix p 현재 윈도우 이전previous 윈도우로 이동하기 prefix 1 첫번째1 윈도우로 이동하기 prefix 5 다섯번째5 윈도우로 이동하기 prefix w 윈도우 리스트를 보여주고 선택하여 이동하기 윈도우 닫기 prefix 로 명령으로 확인 입력y을 받으면 윈도우를 닫을 수삭제할 수 있다 exit 를 입력하여 확인없이 바로 윈도우가 삭제된다 윈도우 이름으로 생성하기 prefix 으로 명령어 입력창을 띄울 수 있다 여기에 newwindow n monitor 라고 입력하고 enter 를 치면 새로운 윈도우에 이름을 지정하여 생성할 수 있다 3 패인 관리 패인pane 만들기 윈도우 안의 구분되는 영역을 패인이라 한다 윈도우를 수평으로 2개의 패인으로 나누거나 수직으로 2개의 패인으로 나눌 수 있다 prefix 윈도우를 수평좌우으로 2개의 패인으로 나눈다 prefix double quote 윈도우를 수직위아래으로 2개의 패인으로 나눈다 패인 이동하기 prefix Left 화살표 좌측 패인으로 이동하기 prefix Right 화살표 우측 패인으로 이동하기 prefix Up 화살표 위 패인으로 이동하기 prefix Downe 화살표 아래 패인으로 이동하기 prefix o 시계 방향으로 패인 이동하기 패인 삭제하기 prefix x 명령으로 현재 선택된 패인을 삭제할 수 있다 exit 로도 삭제가 가능하다 가끔 화면에 키보드 입력이 안돼서 exit 를 화면에 입력할 수 없는 경우가 있다 이 경우에는 명령모드인 prefix x 로 삭제해야 하므로 명령모드도 알아 두는 것이 좋다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=164490&boardType=techBlog&searchData=&page=&subIndex=
플러터(Flutter) 앱을 구성하는 위젯(Widget) 개념 정리해보기,블로그 목적 플러터Flutter 앱을 구성하는 위젯Widget 개념을 정리해본다 블로그 요약 플러터에서 말하는 위젯의 개념을 알아본다 플러터의 위젯에서 말하는 StatelessWidget과 StatefulWidget 을 알아본다 플러터 위젯의 속성과 레이아웃을 간단하게 알아본다 블로그 상세 내용 플러터 기술 블로그를 시작하기전 어떻게 하면 기술블로그가 지루해지지 않을 수 있을까 고민하던중 모든사람의 관심이자 목표 가 될 수 있을지도 모르는 부의추월차선과 저만의 IT기술을 융합 해보면 어떨까 라는 고민을 바탕으로 이 블로그 글이 쓰여졌음을 먼저 상기해드리겠습니다 그럼 우선 엠제이드마코가 말한 부의추월차선 5가지에 대해서 말씀드리고자 합니다 참고로 엠제이드마코의 부의추월차선이라는 책은 정말 제가 사랑하는 책입니다 첫번째 임대 및 배당시스템 두번째 컴퓨터 소프트웨어시스템 세번째 컨텐츠시스템 네번째 유통시스템 다섯번째 인적자원시스템 해당 시스템들의 내용이 궁금하시거나 모르신다면 엠제이 드마코의 부의추월차선을 꼭 읽어 보시길 추천드립니다 그런데 말입니다 왜 뜬금없이 플러터 기술 블로그에 부의추월차선이 등장하냐고요 현재 제가 가지고 있는 돈나무는 배당시스템 컨텐츠시스템유튜브등등 이렇게 2가지를 이중화 해서 가지고 있었습니다 그런데 곰곰히 생각해보니 저의 삶의 가장 많은 부분을 차지하고 있고 열심히 평소에 피땀흘려 공부하며 노력하고 있는 컴퓨터소프트웨어 기술은 서행차선에서 굴리고 있더라고요 그리고 감사하게도 데보션에서 시작된 저의 돈나무들중에 최근에 추가적으로 미국 달러를 벌어오는 유튜브 수익화를 달성했는데요 현재는 비록소소한 수익이지만요 이 감성 과 feel 를 가지고 컴퓨터소프트웨어기술플러터 를 융합시킨 저만의 새로운 돈나무 를 개척해보고자 합니다 워렌버핏이 말했다죠 잠자는 동안에도 돈이 들어오는 방법을 찾지 못한다면 당신은 죽을때 까지 일을 해야만 할 것이다 이거 진짜 무서운 말아닙니까 아무튼 정리하자면 이제 플러터를 통해서 아래 씨앗2 컴퓨터 소프트웨어 시스템을 만들어보고자 합니다 물론 아직은 플러터를 공부하는단계라서요꾸준히 한번 해보려고요 출처 엠제이드마코 부의추월차선 5가지 씨앗 중에서 개인적인 썰은 여기서 그만하고요 본격적으로 플러터에 대해서 알아보시죠 우선 플러터Flutter의 개념과 플러터 앱에서 말하는 위젯의 개념은 무엇일까요 플러터는 구글에서 개발한 UI 프레임워크로 크로스 플랫폼 앱 개발을 위해 사용됩니다 플러터 앱은 위젯을 기반으로 구성되며 위젯은 앱의 UI 요소를 구축하는 데 필요한 기본 단위입니다 그럼 위젯에 대해 자세히 알아보도록 하겠습니다 1 위젯의 개념 위젯은 플러터 앱의 모든 시각적 요소를 표현합니다 버튼 텍스트 이미지 등 사용자 인터페이스의 모든 요소는 위젯으로 표현됩니다 플러터에서는 모든 것이 위젯이라고 할 수 있습니다 2 위젯의 종류 플러터에서는 크게 두 가지 종류의 위젯을 사용합니다 StatelessWidget과 StatefulWidget 가 StatelessWidget 한 번 그려진 후에는 변경되지 않는 위젯입니다 예를 들어 앱의 로고 이미지나 정적인 텍스트를 표시하는 데 사용됩니다 이 상속 트리에서 StatelessWidget은 최상위 부모 클래스입니다 StatelessWidget을 상속하는 다양한 클래스들이 있으며 여기에는 Text Image Container Row Column ListView 등의 클래스가 포함됩니다 그리고 Text 에 대해서 좀 더 자세하게 보시면 아래와 같습니다 위에서 아래로 내려갈수록 상속 관계가 깊어지며 가장 아래에 있는 Text가 최종적인 위젯입니다 Object 모든 플러터 객체의 기본 클래스입니다 Diagnosticable 진단 정보를 제공하기 위한 추상 클래스입니다 DiagnosticableTree 진단 정보를 트리 구조로 제공하기 위한 추상 클래스입니다 Widget 플러터의 위젯을 나타내기 위한 추상 클래스입니다 StatelessWidget 상태를 가지지 않는 위젯을 나타내기 위한 추상 클래스입니다 Text 텍스트를 나타내는 위젯입니다 주어진 텍스트를 화면에 표시할 수 있습니다 나StatefulWidget 상태를 가지고 있으며 상태가 변경될 때마다 UI가 업데이트됩니다 예를 들어 사용자의 입력에 따라 동적으로 변경되는 버튼이나 폼 필드 등에 사용됩니다 이 상속 트리에서 StatefulWidget은 최상위 부모 클래스입니다 StatefulWidget을 상속하는 다양한 클래스들이 있으며 여기에는 TextButton IconButton Checkbox Radio TextFormField DropdownButton 등의 클래스가 포함됩니다 그리고 TextButton 에 대해서 좀 더 자세하게 보시면 아래와 같습니다 위에서 아래로 내려갈수록 상속 관계가 깊어지며 가장 아래에 있는 TextButton이 최종적인 위젯입니다 Object 모든 플러터 객체의 기본 클래스입니다 Diagnosticable 진단 정보를 제공하기 위한 추상 클래스입니다 DiagnosticableTree 진단 정보를 트리 구조로 제공하기 위한 추상 클래스입니다 Widget 플러터의 위젯을 나타내기 위한 추상 클래스입니다 StatefulWidget 상태를 가지는 위젯을 나타내기 위한 추상 클래스입니다 내부적으로 State 객체를 가집니다 MaterialButton 머티리얼 디자인 스타일을 가지는 버튼 위젯을 나타냅니다 TextButton은 MaterialButton의 하위 클래스입니다 TextButton 텍스트를 보여주고 사용자 입력에 반응하는 버튼 위젯입니다 일반적으로 눌렀을 때 어떤 작업을 수행하기 위해 사용됩니다 3 위젯의 계층 구조 플러터 앱은 위젯의 계층 구조로 이루어져 있습니다 각 위젯은 부모 위젯과 자식 위젯을 가질 수 있으며 이를 통해 복잡한 UI를 구성할 수 있습니다 부모 위젯은 자식 위젯을 가지고 있으며 자식 위젯은 다시 자신의 부모가 될 수 있습니다 4 위젯의 속성과 레이아웃 위젯은 다양한 속성을 가지고 있어서 해당 위젯의 모양 크기 색상 등을 조절할 수 있습니다 플러터에서는 위젯의 속성을 변경하여 레이아웃을 조정하거나 스타일을 적용할 수 있습니다 예를들자면요 다음은 플러터에서 위젯의 속성을 변경하여 레이아웃을 조정하고 스타일을 적용하는 예시 코드입니다 이 예시에서는 Container 위젯을 사용하여 레이아웃을 구성하고 BoxDecoration을 사용하여 스타일을 적용합니다 import packagefluttermaterialdart void main runAppMyApp class MyApp extends StatelessWidget override Widget buildBuildContext context return MaterialApp title Widget Styling Example home Scaffold appBar AppBar title TextWidget Styling Example body Center child Container width 200 너비 조절 height 200 높이 조절 decoration BoxDecoration color Colorsblue 배경색상 변경 borderRadius BorderRadiuscircular10 테두리 모서리 둥글게 조절 boxShadow BoxShadow color Colorsgrey offset Offset0 2 그림자 위치 조절 blurRadius 4 그림자 흐릿한 정도 조절 child Text Styled Container style TextStyle color Colorswhite 텍스트 색상 변경 fontSize 20 텍스트 크기 조절 fontWeight FontWeightbold 텍스트 굵기 조절 이 코드는 앱의 화면에 한 가운데에 위치한 스타일이 적용된 Container 위젯을 생성합니다 Container의 속성을 변경하여 위젯의 크기 배경색 테두리 모양 그림자 등을 조정할 수 있습니다 또한 Container 안에 Text 위젯을 추가하여 텍스트의 색상 크기 굵기 등도 조절할 수 있습니다 위의 예시 코드 내용을 간단하게 설명해보자면요 Container의 속성을 변경하여 레이아웃을 조정합니다 예시에서는 width와 height 속성을 사용하여 박스의 크기를 200x200으로 조절하였습니다 Container의 decoration 속성을 사용하여 스타일을 적용합니다 BoxDecoration은 박스의 배경색 테두리 그림자 등을 설정하는 데 사용됩니다 예시에서는 color 속성을 사용하여 박스의 배경색을 파란색으로 변경하였고 borderRadius 속성을 사용하여 테두리의 모서리를 둥글게 조절하였습니다 또한 boxShadow 속성을 사용하여 박스에 그림자 효과를 추가하였습니다 Container 내부에 Text 위젯을 추가하여 텍스트를 표시하고 스타일을 적용합니다 Text 위젯의 style 속성을 사용하여 텍스트의 색상 크기 굵기 등을 조절할 수 있습니다 예시에서는 텍스트의 색상을 흰색으로 크기를 20로 굵기를 굵은 글꼴로 변경하였습니다 위의 예시 코드를 실행하면 앱 화면에는 스타일이 적용된 박스가 중앙에 표시됩니다 이 예시를 통해 플러터에서 위젯의 속성을 변경하여 레이아웃을 조정하고 스타일을 적용하는 방법을 이해할 수 있습니다 안드로이드 스튜디오를 사용해서 한번 실행해보면요 에뮬레이터에서 아래와 같은 결과를 확인할 수 있습니다 간단하게 색상을 빨간색으로 변경해볼까요 아래와 같이 color 를 기존 blud 에서 red 로 바꿔볼께요 그럼 아래와 같이 배경색상이 red로 바뀐것을 확인해볼 수 있습니다 5 위젯 트리와 화면 그리기 플러터는 위젯 트리를 사용하여 화면을 그립니다 참고로 위젯 트리는 부모 위젯과 자식 위젯들이 계층 구조로 연결된 구조를 말합니다 앱의 시작점은 최상위 위젯인 MaterialApp 위젯입니다 MaterialApp은 앱의 전반적인 구성을 정의하고 화면 라우팅 테마 설정 등의 기능을 제공합니다 MaterialApp 위젯의 자식으로는 주로 Scaffold 위젯이 사용되며 Scaffold는 앱의 기본 레이아웃 구조를 정의합니다 Scaffold 위젯 내부에는 AppBar 위젯과 Body 위젯이 포함됩니다 AppBar 위젯은 상단에 앱의 타이틀이나 액션 버튼을 표시하는 데 사용되며 Body 위젯은 앱의 실제 콘텐츠를 표시하는 데 사용됩니다 Body 위젯은 다양한 위젯으로 구성될 수 있으며 예를 들어 Column ListView Container 등을 사용하여 콘텐츠를 배치하고 스크롤 가능한 영역을 만들 수 있습니다 또한 위젯은 특정 이벤트에 반응하거나 사용자 입력을 처리하기 위해 사용될 수도 있습니다 예를 들어 RaisedButton 위젯은 사용자가 버튼을 클릭할 때 특정 동작을 수행하도록 할 수 있습니다 플러터는 위젯의 상태 변화를 감지하고 자동으로 UI를 업데이트하는 핫 리로딩 기능을 제공하여 개발자가 쉽게 UI를 수정하고 확인할 수 있도록 합니다 참고로 위젯은 다양한 속성과 메서드를 가지고 있어 개발자가 원하는 대로 UI를 구성하고 조작할 수 있습니다 또한 플러터는 다양한 내장 위젯을 제공하며 필요에 따라 사용자 정의 위젯을 만들 수도 있습니다 마지막으로 플러터에서는 위젯 간의 효율적인 통신을 위해 상태 관리 패턴인 Provider Riverpod Bloc 등을 사용할 수 있습니다 이를 통해 위젯 간 데이터 공유와 상태 관리를 용이하게 할 수 있습니다 아무튼 위의 패턴들도 한번 다음 이어지는 블로그에서 다뤄보도록 하겠습니다 이상으로 플러터 앱에서 말하는 위젯의 개념에 대해 간략하게 정리해보았고요 그리고 앞으로도 플러터관련 공부한 내용들을 정리해나갈까 합니다 한편 저의 목표인 부의 추월 차선 2번째 씨앗 컴퓨터소프트웨어시스템을 통한 돈나무를 세워볼까 하니깐요 많은 관심과 애정 부탁드려요 아무튼 오늘의 블로그는 여기까지고요 항상 믿고 봐주셔서 감사합니다 결론 위젯의 개념 위젯은 플러터 앱의 모든 시각적 요소를 표현합니다 버튼 텍스트 이미지 등 사용자 인터페이스의 모든 요소는 위젯으로 표현됩니다 플러터에서는 모든 것이 위젯이라고 할 수 있습니다 위젯의 종류 플러터에서는 크게 두 가지 종류의 위젯을 사용합니다 StatelessWidget과 StatefulWidget 그외에 위젯의 여러특징들도 꼭 머릿속에 정리해두시면 좋겠네요 그리고 더욱 가슴에 묻어야할 구절은 바로 워렌버핏이 말했다죠 잠자는 동안에도 돈이 들어오는 방법을 찾지 못한다면 당신은 죽을 때까지 일을 해야만 할 것이다 부디 이글을 읽으시는 모든분들께서는 잠자는 동안에도 돈이 들어오는 방법 을 꼭 만들어보시는 서막이 되시길 간절히 기원하면서 블로그를 마치겠습니다 긴글 읽어주셔서 진심으로 감사합니다 다음에 더 좋은 컨텐츠로 찾아뵐 수 있도록 더욱 노력하는 제가 되겠습니다 Ill be back 그리고 조금이나마 제 글이 도움이 되셨다면 아래 배너 링크를 통해서 네이버인플루언서 팬이되주시면 제가 컨텐츠를 생산하는데 큰 도움이 될것 같습니다 나의 목표 및 다짐을 항상 내곁에 두기 목표 나의 강점을 바탕으로 나의 일을 잘해냄으로써 타인과 사회를 아릅답게 만든다 현재 내가 가진 능력으로 누군가에 도움이 될 수 있을까 에 대해서 항상 생각하기 나는 블로그 생태계에서 IT 테크관련 파워블로거가 반드시 된다 유튜브 시장을 호령하는 100만 유튜버가 반드시 된다 feat 100만 유튜버가 반드시 될 매직 나는 꾸준히 공부하고 공부한것을 실천하는 창의적인 개발자가 된다 feat devocean 개발운영자가될 매직 목표를 이루기 위한 실천방안 꾸준한 블로깅기록법독서법으로 넘버원이 아닌 온리원이 되보자 천사불여일행을 항상생각하며 체화 및 각인시키자 천번 생각하는것보다 한번 행동하는 것이 더 중요하다 기기일약 불능십보 노마십가 공재불사 천리마도 한번에 열걸음을 뛸 수 없고 느리고 둔한말이라도 열흘이면 하룻길을 간다 모든 실수에는 마술이 숨어 있다 따라서 나는 실수하면 실수할수록 그런 실수에서 더 많이 배울수록 삶에서 더 많은 마술을 갖는다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=165056&boardType=techBlog&searchData=&page=&subIndex=
@coohde,Next.js 13 - 16. 글 삭제,https://img.youtube.com/vi/AgtBj7XVToQ/0.jpg,https://www.youtube.com/watch?v=AgtBj7XVToQ
@jocoding,내 서비스로 금융 대기업의 투자와 협업 기회를?! || 엔터플 싱커톤 시즌 3,https://img.youtube.com/vi/_8hHVXbKvDY/0.jpg,https://www.youtube.com/watch?v=_8hHVXbKvDY
2023 데보션 전문가의 첫 항해가 시작되었습니다 - OT현장 스케치,2023 데보션 전문가 프로그램에 참여해준 SK 그룹개발자분들 드디어 처음 만나는 올해 첫 정기 모임 자리가 을지로 T타워와 SK텔레콤 분당사옥에서 양일간 진행되었습니다 첫 모임인 만큼 오프라인임에도 많은 개발자분들이 참여해주셨는데요 지금 그 뜨거운 첫 만남의 현장을 생생히 소개드립니다 현장의 분위기는 어땠을까요 처음 만나는 서먹함도 잠시 서로 다른 여러 회사에서 만난 만큼 다양한 관심사들을 서로 주고 받으면서 빠르게 친해졌답니다 한해의 프로그램과 일정을 소개받는 시간부터 다과를 겸한 네트워킹의 시간 그리고 음식과 함께한 찐한 뒷풀이까지 함께했는데요 보다 다채로운 프로그램으로 더 즐겁고 신나는 개발 생활을 할 수 있는 2023의 데보션 전문가 프로그램 그 뜨거웠던 첫 만남의 현장을 잠시 살펴 볼까요 더욱 풍성하고 다채로워진 데보션 전문가 프로그램 2023 데보션 전문가 프로그램은 전년보다 더 강력하고 파워풀한 콘텐츠로 꽉꽉 채워서 돌아왔습니다 데보션 운영자 김상기 담당자의 한해 계획으로 OT가 진행되었는데요 다양한 체험과 학습 성장의 기회를 제공하는 것은 물론 대내외적으로 본인의 개발 지식과 경험을 공유하는 기회를 대폭 강화해 제공할 계획인데요 여기에 올해는 그룹내 비슷한 분야의 개발자 분들과 다양한 소통의 기회를 만들어나갈 예정입니다 이 모든 성장의 경험과 개발 인사이트들로 채워질 데보션 벌써 기대되지 않나요 첫 모임 찐 후기가 궁금합니다 양필규SK텔레콤 사내 TCLTech Collabo Lab에서 법무팀 RD 팀 등 그간 접점이 없었던 동료들과 일과 외 시간의 연구모임 활동이 즐거운 경험으로 남아 있어 매년 활동을 하면서 영위하는 비즈니스만큼 다양한 그룹 구성원들과의 교류도 의미있을 것 같다는 생각을 평소 하고 있었습니다 OT때 많은 분들을 뵙지는 못했지만 역시나 진취적인 분들 배울점이 많은 분들과의 만남이었습니다 다양한 배경 다양한 기술요소의 전문가 그룹인 만큼 사회문제 또는 비즈니스 문제와 연결되어 가치있는 의미있는 문제해결의 장 사례도 만들어지기를 희망합니다 이동준SK커뮤니케이션즈 제가 좋아라하는 닭과 데보션 마스터님들과 함께한 데보션 OT 참석소견을 간단히 정리하자면요 이렇게 다시한번 OT를 통해서 만나뵙게되어서 정말로 감사하고 행복하고 기쁜 시간이였습니다 앞으로도 더욱 함께 유쾌하고 행복한 데보션 활동들이 되었으면 좋겠습니다 저도 열심히 도전하고 이뤄나가도록 하겠습니다 심재훈 SK하이닉스 OT때 SK 그룹사 개발자분들 만나뵐수 있어서 좋았습니다 특히 하이닉스분들 많이 참가해서 반가웠고 23년도에 데보션과 같이 즐거운 개발문화 만들어 나갔으면 좋겠습니다 윤주성SKTelecom 안녕하세요 SK텔레콤 윤주성입니다 언어모델 개발업무를 하고 있습니다 다양한 분들을 만나서 OT 참여하길 잘했다는 생각이들었네요 앞으로도 잘부탁드리겠습니다 신정민SKTelecom ifland라는 메타버스 SNS 서비스 백엔드쪽 개발을 하고 있습니다 SK그룹사 여러분들을 만나서 반가웠습니다 개인적으로 많은 분들이 Devocean과 함께 성장할 수 있는 한해가 되었으면 합니다 이하진SK하이닉스 개발자 모임에 참석할 수 있는 기회를 주셔서 감사합니다 다양한 분들을 만났고 앞으로도 좋은 인연 발전의 시간이 되기를 희망합니다 OT 또한 너무 즐거운 시간이었습니다 앞으로도 오프모임에 열심히 참석하도록 하겠습니다 하봉래SK하이닉스 지난주 OT에서 DEVOCEAN의 그동안의 노력들과 추구하는 방향에 대해서 설명을 잘 들었습니다 저도 그 방향에 많은 힘이 될 수 있도록 열심히 활동 하겠습니다 김예슬SK하이닉스 DEVOCEAN 활동을 통해 제조업이나 데이터 분석 뿐만 아니라 여러 분야의 전문가 분들과 함께할 수 있어서 매우 설레네요 다른 마스터분들이 저에게 많은 도움과 자극이 되어주시듯 저 또한 열심히 활동하도록 하겠습니다 잘 부탁드립니다 김정석SK텔레콤 데보션은 일반적인 사무 절차로는 지원 받기 어려운 부분을 해결해줄 뿐아니라 유사 업무를 수행하는 분들하고 고충을 털어놓는 자리도 마련해주어서 꾸준히 도움을 받고 있습니다 올해는 데보션이 잘 발전할 수 있도록 양질의 컨텐츠를 공급하려고 노력하겠습니다 감사합니다 김진SK텔레콤 에이닷 언어모델 개발업무를 하고 있습니다 OT때 하이닉스나 CC 등 그룹사 분들을 만나뵐 수 있어서 좋았습니다 앞으로 데보션 이용자가 많아지면 좋겠습니다 최재영 SKCC 금요일 OT에 참석해서 짧은 시간이었지만 개발과 기술에 눈이 반짝이시는 분들과 함께 이야기할 수 있어서 너무 즐거웠습니다 목요일에 더 많은 분들이 계셨다고 해서 다음 번 밋업도 더욱 기대가 됩니다 지태권SK하이닉스 안녕하세요 SK hynix 에 다니는 지태권 입니다 소개가 늦었네요 저는 실리콘벨리의 테크회사에 다니다가 지난2018년 하반기에 SK 하이닉스에 조인하게 되었습니다 OT 때 소개된 데로 미국 회사들은 개발자 네트워크가 매우 활발히 진행되고 서로 코드 리뷰까지고 해주는것이 일상입니다 하이닉스와서 좀 부족하다 생각해 문화를 바꿔보고자 했는데 이런 그룹 전사적인 공간이 있었다는 것을 뒤늦게 알아 조인하게 되었습니다 앞으로 Devocean에서 그룹 전체 문화를 개발자 friendly 하게 하는데 기여하고 싶습니다 감사합니다 오세진SK하이닉스 OT 통해 Devocean 활동 영역과 역할을 알게 되니 현업 업무에도 refresh가 되었습니다 앞으로 잘 부탁드리겠습니다 한 해동안 현업의 현장에서 일어나는 다양한 개발 경험을 공유해 주시면서 즐거운 개발생활을 함께할 117명의 개발자분들 데보션 곳곳에서 만나뵐 수 있을테니 많은 기대 부탁드립니다 데보션 전문가란 데보션 전문가는 SK 그룹의 개발자로 각 사의 현업에서 개발 업무를 진행하면서 다양한 개발경험을 공유합니다 비슷한 업무분야의 개발자를 만나 개발 고민을 함께 해결하는 기회를 마련 하는 것은 물론 개발 멘토링 및 외부 행사등에 참여하는 개발자 성장을 위한 참여형 프로그램에 지원 선발되신 분들입니다,https://i.ibb.co/Xz71My9/2024-01-04-173243.png,https://devocean.sk.com/blog/techBoardDetail.do?ID=164562&boardType=techBlog&searchData=&page=&subIndex=
"사상 첫 민간 달 착륙선 탄생할까…미 우주기업, ‘페레그린’ 발사","벌컨 센타우르 로켓에는 사상 첫 민간 달 착륙을 목표로 한 우주선 ‘페레그린’이 실렸다.
달에 내린 민간 달 착륙선 ‘페레그린’의 상상도.
페레그린이 다음 달 23일 예정대로 월면에 안착하면 ‘민간 첫 달 착륙선’이라는 기록을 세우게 된다.
‘민간이 주도한 사상 첫 월면 안착’이라는 타이틀을 따내기 위한 무인 달 착륙선이 미국에서 8일(현지시간) 발사됐다.
다음 달 예정대로 월면 착륙에 성공한다면 20세기 후반부터 줄곧 국가가 주도했던 달 개척 활동이 민간기업으로 확대되는 결정적인 계기가 될 것으로 보인다.
미국 민간우주기업 애스트로보틱은 이날 오전 2시18분(한국시간 오후 4시18분)에 미 플로리다주 케이프커내버럴 우주군기지에서 자신들이 개발한 달 착륙선 ‘페레그린’을 발사했다.
페레그린은 약 한 달 반 동안 우주공간을 비행하다가 다음 달 23일 달 착륙을 시도한다.
만약 착륙에 성공하면 페레그린은 ‘사상 첫 민간 달 착륙선’이라는 기록을 세우게 된다.
한편 다음 달 중순에는 또 다른 미국 민간기업 인튜이티브 머신이 만든 무인 달 착륙선 ‘노바-C’가 일론 머스크가 이끄는 스페이스X 로켓에 실려 발사된다.
대략 다음 달 하순, 월면 안착을 시도할 것으로 예상된다.",https://imgnews.pstatic.net/image/032/2024/01/08/0003272124_001_20240108172001111.png?type=w647,https://n.news.naver.com/mnews/article/032/0003272124?sid=105
